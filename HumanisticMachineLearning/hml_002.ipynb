{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit-learn digits dataset example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/admin/github/wordroid.sblo.jp/lib')\n",
    "from keras_ex.GaussianKernel import GaussianKernel, GaussianKernel2, GaussianKernel3\n",
    "\n",
    "# or copy and paste the definition of `GaussianKernel` here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import cluster, datasets, mixture\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.layers import Input, Embedding, LSTM, GRU, Dense, Dropout, Lambda, \\\n",
    "    Conv1D, Conv2D, Conv3D, \\\n",
    "    Conv2DTranspose, \\\n",
    "    AveragePooling1D, \\\n",
    "    MaxPooling1D, MaxPooling2D, MaxPooling3D, \\\n",
    "    GlobalAveragePooling1D, \\\n",
    "    GlobalMaxPooling1D, GlobalMaxPooling2D, \\\n",
    "    LocallyConnected1D, LocallyConnected2D, \\\n",
    "    concatenate, Flatten, Average, Activation, \\\n",
    "    RepeatVector, Permute, Reshape, Dot, \\\n",
    "    multiply, dot, add, \\\n",
    "    PReLU, \\\n",
    "    Bidirectional, TimeDistributed, \\\n",
    "    SpatialDropout1D, \\\n",
    "    BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "from keras import losses\n",
    "from keras.callbacks import BaseLogger, ProgbarLogger, Callback, History\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import regularizers\n",
    "from keras import initializers\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.constraints import maxnorm, non_neg\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape((X.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sc = X / 16.0\n",
    "X_sc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1078, 64)\n",
      "(719, 64)\n",
      "(1078,)\n",
      "(719,)\n"
     ]
    }
   ],
   "source": [
    "X_sc_train, X_sc_test, y_train, y_test = train_test_split(X_sc, y, test_size=0.4, random_state=0)\n",
    "print(X_sc_train.shape)\n",
    "print(X_sc_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cat = to_categorical(y)\n",
    "y_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1078, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cat_train = to_categorical(y_train)\n",
    "y_cat_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(719, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cat_test = to_categorical(y_test)\n",
    "y_cat_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lm(smpl, y, num_lm0=20, random_state=0):\n",
    "    cls = sorted(np.unique(y))\n",
    "    np.random.seed(random_state)\n",
    "    num_feature = np.prod(smpl.shape[1:])\n",
    "    shape = np.hstack([num_lm0, smpl.shape[1:]])\n",
    "    num_lm = num_lm0 * len(cls)\n",
    "    init_list = []\n",
    "    for ii in cls:\n",
    "        init_wgt0 = smpl[y==ii]\n",
    "        init_wgt0 = init_wgt0[np.random.choice(range(init_wgt0.shape[0]), size=num_lm0, replace=False)] + \\\n",
    "                    np.random.normal(scale=0.002, size=num_lm0*num_feature).reshape(shape)\n",
    "        init_list.append(init_wgt0)\n",
    "    init_wgt = np.vstack(init_list)\n",
    "    init_wgt = init_wgt[np.random.permutation(range(init_wgt.shape[0]))]\n",
    "    return init_wgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faea239fd68>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9l+8Q5/pEyhkXAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faebc2d02e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[0].reshape((8,8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "chose landmarks on input data\n",
    "pick 20 data each digit\n",
    "'''\n",
    "num_lm0 = 20\n",
    "num_lm = num_lm0 * 10\n",
    "\n",
    "init_wgt = get_lm(X_sc_train, y_train, num_lm0=num_lm0)\n",
    "init_wgt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 200)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.72150955,  0.73561866,  0.82786211, ...,  0.41821092,\n",
       "         0.89579757,  0.91663392],\n",
       "       [ 0.53282433,  0.95938975,  0.4606461 , ...,  0.34725582,\n",
       "         0.52960293,  0.74073731],\n",
       "       [ 0.19641256,  0.93073513,  0.27859638, ...,  0.40815083,\n",
       "         0.74430385,  0.842343  ],\n",
       "       ..., \n",
       "       [ 0.03160016,  0.13718324,  0.13656883, ...,  0.02309561,\n",
       "         0.84539496,  0.80830776],\n",
       "       [ 0.99771232,  0.54711599,  0.12419023, ...,  0.12487177,\n",
       "         0.31043308,  0.99672953],\n",
       "       [ 0.1143734 ,  0.87510768,  0.00171543, ...,  0.69388459,\n",
       "         0.66499431,  0.46904023]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "chose landmarks randomly for gk2\n",
    "'''\n",
    "#num_lm2 = 200\n",
    "num_lm2 = 10\n",
    "init_lm2 = np.random.random_sample((num_lm2, num_lm))\n",
    "print(init_lm2.shape)\n",
    "init_lm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_cls (InputLayer)           (None, 10)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_img (InputLayer)           (None, 64)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_cls_img (Model)            (None, 64)            26305       input_cls[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "model_img_img (Model)            (None, 64)            25665       input_img[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "pass_cls_img (Activation)        (None, 64)            0           model_cls_img[1][0]              \n",
      "____________________________________________________________________________________________________\n",
      "pass_img_imgA (Activation)       (None, 64)            0           model_img_img[2][0]              \n",
      "____________________________________________________________________________________________________\n",
      "pass_fit_imgA (Lambda)           (None, 64)            0           pass_img_imgA[0][0]              \n",
      "                                                                   pass_cls_img[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 26,305\n",
      "Trainable params: 26,305\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "def make_modelz(wgt_embed=None):\n",
    "    '''==============================\n",
    "    inputs\n",
    "    =============================='''\n",
    "    inp_cls = Input(shape=(10,), name='input_cls')\n",
    "    inp_img = Input(shape=(64,), name='input_img')\n",
    "    inp_200 = Input(shape=(num_lm,), name='input_200')\n",
    "    \n",
    "    '''==============================\n",
    "    layers\n",
    "    =============================='''\n",
    "    if wgt_embed is None:\n",
    "        layer_dense_embed = Dense(64, use_bias=False, name='embed')\n",
    "    else:\n",
    "        layer_dense_embed = Dense(64, use_bias=False, name='embed', weights=[wgt_embed])\n",
    "    layer_dense_ae = Dense(64, name='dense_ae')\n",
    "    \n",
    "    '''Gaussian Kernel 1'''\n",
    "    weights1 = [init_wgt, np.log(np.array([1./(2.*64*0.1)]))]\n",
    "    layer_gk1 = GaussianKernel3(num_lm, 64, name='gkernel1', weights=weights1)\n",
    "    \n",
    "    '''Gaussian Kernel 2'''\n",
    "    weights2 = [init_lm2, np.log(np.array([1./(2.*num_lm*0.1)]))]\n",
    "    layer_gk2 = GaussianKernel3(10, num_lm, weights=weights2, name='gkernel2')\n",
    "    \n",
    "    '''==============================\n",
    "    models\n",
    "    =============================='''\n",
    "    oup_gk1 = layer_gk1(inp_img)\n",
    "    model_gk1 = Model(inp_img, oup_gk1, name='model_gk1')\n",
    "    \n",
    "    oup_gk2 = layer_gk2(inp_200)\n",
    "    model_classify = Model(inp_200, oup_gk2, name='model_classify')\n",
    "    \n",
    "    model_embed = Model(inp_cls, layer_dense_embed(inp_cls), name='model_embed')\n",
    "    \n",
    "    # ae\n",
    "    oup_ae = layer_dense_ae(inp_200)\n",
    "    model_ae = Model(inp_200, oup_ae, name='model_ae')\n",
    "    \n",
    "    # img > img\n",
    "    oup_img_img = model_ae(oup_gk1)\n",
    "    oup_img_img = Activation('sigmoid', name='output_img')(oup_img_img)\n",
    "    model_img_img = Model(inp_img, oup_img_img, name='model_img_img')\n",
    "    \n",
    "    # img > cls\n",
    "    oup_img_cls = model_classify(oup_gk1)\n",
    "    model_img_cls = Model(inp_img, oup_img_cls, name='model_img_cls')\n",
    "    \n",
    "    # cls > img\n",
    "    model_cls_img = Model(inp_cls, model_img_img(model_embed(inp_cls)), name='model_cls_img')\n",
    "    \n",
    "    # cls > cls\n",
    "    model_cls_cls = Model(inp_cls, model_img_cls(model_embed(inp_cls)), name='model_cls_cls')\n",
    "    \n",
    "    '''==============================\n",
    "    cost functions\n",
    "    =============================='''\n",
    "    def cost_cls(y_true, y_pred):\n",
    "        return losses.categorical_crossentropy(y_true, y_pred)\n",
    "    def cost_ae(y_true, y_pred):\n",
    "        return losses.mse(y_true, y_pred)\n",
    "    def cost_zero(y_true, y_pred):\n",
    "        return losses.mse(0, y_pred)\n",
    "    \n",
    "    '''=== img -> imgA ==='''\n",
    "    pass_img_imgA = model_img_img(inp_img)\n",
    "    pass_img_imgA = Activation('linear', name='pass_img_imgA')(pass_img_imgA)\n",
    "    \n",
    "    '''=== cls -> img ==='''\n",
    "    pass_cls_img = model_cls_img(inp_cls)\n",
    "    pass_cls_img = Activation('linear', name='pass_cls_img')(pass_cls_img)\n",
    "    \n",
    "    '''=== cls -> img -> cls ==='''\n",
    "    pass_cls_img_cls = model_img_cls(pass_cls_img)\n",
    "    model_cls_img_cls = Model(inp_cls, pass_cls_img_cls, name='model_cls_img_cls')\n",
    "    pass_cls_img_cls = Activation('softmax', name='pass_cls_img_cls')(pass_cls_img_cls)\n",
    "    \n",
    "    pass_fit_imgA = Lambda(lambda x: x[0] - x[1], name='pass_fit_imgA')([\n",
    "        pass_img_imgA,\n",
    "        pass_cls_img\n",
    "    ])\n",
    "    \n",
    "    model = Model([inp_img, inp_cls],\n",
    "                  [pass_cls_img, pass_fit_imgA])\n",
    "    model.compile(loss={\n",
    "                     'pass_cls_img': cost_ae,\n",
    "                     'pass_fit_imgA': cost_zero,\n",
    "                  },\n",
    "                  loss_weights={\n",
    "                     'pass_cls_img': 1.0,\n",
    "                     'pass_fit_imgA': 1.0,\n",
    "                  },\n",
    "                  metrics=['accuracy'],\n",
    "                  optimizer='adam')\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'model_embed': model_embed,\n",
    "        'model_ae': model_ae,\n",
    "        'model_gk1': model_gk1,\n",
    "        'model_classify': model_classify,\n",
    "        \n",
    "        'model_img_img': model_img_img,\n",
    "        'model_img_cls': model_img_cls,\n",
    "        'model_cls_img': model_cls_img,\n",
    "        'model_cls_cls': model_cls_cls,\n",
    "        \n",
    "        'model_cls_img_cls': model_cls_img_cls,\n",
    "    }\n",
    "\n",
    "models = make_modelz()\n",
    "model = models['model']\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"264pt\" viewBox=\"0.00 0.00 352.00 264.00\" width=\"352pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 260)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-260 348,-260 348,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140388457059160 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140388457059160</title>\n",
       "<polygon fill=\"none\" points=\"10.5,-219.5 10.5,-255.5 144.5,-255.5 144.5,-219.5 10.5,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"77.5\" y=\"-233.8\">input_cls: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140387925323504 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140387925323504</title>\n",
       "<polygon fill=\"none\" points=\"5,-146.5 5,-182.5 150,-182.5 150,-146.5 5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"77.5\" y=\"-160.8\">model_cls_img: Model</text>\n",
       "</g>\n",
       "<!-- 140388457059160&#45;&gt;140387925323504 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140388457059160-&gt;140387925323504</title>\n",
       "<path d=\"M77.5,-219.313C77.5,-211.289 77.5,-201.547 77.5,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"81.0001,-192.529 77.5,-182.529 74.0001,-192.529 81.0001,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140388457059720 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140388457059720</title>\n",
       "<polygon fill=\"none\" points=\"188.5,-219.5 188.5,-255.5 328.5,-255.5 328.5,-219.5 188.5,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"258.5\" y=\"-233.8\">input_img: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140387925272000 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140387925272000</title>\n",
       "<polygon fill=\"none\" points=\"182.5,-146.5 182.5,-182.5 334.5,-182.5 334.5,-146.5 182.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"258.5\" y=\"-160.8\">model_img_img: Model</text>\n",
       "</g>\n",
       "<!-- 140388457059720&#45;&gt;140387925272000 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140388457059720-&gt;140387925272000</title>\n",
       "<path d=\"M258.5,-219.313C258.5,-211.289 258.5,-201.547 258.5,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"262,-192.529 258.5,-182.529 255,-192.529 262,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140387923806976 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140387923806976</title>\n",
       "<polygon fill=\"none\" points=\"0,-73.5 0,-109.5 155,-109.5 155,-73.5 0,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"77.5\" y=\"-87.8\">pass_cls_img: Activation</text>\n",
       "</g>\n",
       "<!-- 140387925323504&#45;&gt;140387923806976 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140387925323504-&gt;140387923806976</title>\n",
       "<path d=\"M77.5,-146.313C77.5,-138.289 77.5,-128.547 77.5,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"81.0001,-119.529 77.5,-109.529 74.0001,-119.529 81.0001,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140387924557048 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140387924557048</title>\n",
       "<polygon fill=\"none\" points=\"173,-73.5 173,-109.5 344,-109.5 344,-73.5 173,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"258.5\" y=\"-87.8\">pass_img_imgA: Activation</text>\n",
       "</g>\n",
       "<!-- 140387925272000&#45;&gt;140387924557048 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140387925272000-&gt;140387924557048</title>\n",
       "<path d=\"M258.5,-146.313C258.5,-138.289 258.5,-128.547 258.5,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"262,-119.529 258.5,-109.529 255,-119.529 262,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140387922681752 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140387922681752</title>\n",
       "<polygon fill=\"none\" points=\"93,-0.5 93,-36.5 242,-36.5 242,-0.5 93,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"167.5\" y=\"-14.8\">pass_fit_imgA: Lambda</text>\n",
       "</g>\n",
       "<!-- 140387923806976&#45;&gt;140387922681752 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140387923806976-&gt;140387922681752</title>\n",
       "<path d=\"M99.2865,-73.3129C110.894,-64.1558 125.339,-52.76 137.945,-42.8158\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"140.231,-45.4704 145.914,-36.5288 135.895,-39.9746 140.231,-45.4704\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140387924557048&#45;&gt;140387922681752 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140387924557048-&gt;140387922681752</title>\n",
       "<path d=\"M236.471,-73.3129C224.735,-64.1558 210.129,-52.76 197.384,-42.8158\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"199.363,-39.9208 189.326,-36.5288 195.057,-45.4397 199.363,-39.9208\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/miniconda3/envs/da02/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:95: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fae96173f60>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit({'input_img': X_sc_train, 'input_cls': y_cat_train},\n",
    "          {\n",
    "              'pass_cls_img': X_sc_train,\n",
    "              'pass_fit_imgA': X_sc_train,\n",
    "          },\n",
    "          validation_data=(\n",
    "              {'input_img': X_sc_test, 'input_cls': y_cat_test},\n",
    "              {\n",
    "                  'pass_cls_img': X_sc_test,\n",
    "                  'pass_fit_imgA': X_sc_test,\n",
    "              }\n",
    "          ),\n",
    "          verbose=0,\n",
    "          batch_size=32,\n",
    "          epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit({'input_img': X_sc_train, 'input_cls': y_cat_train},\n",
    "          {\n",
    "              'pass_cls_img': X_sc_train,\n",
    "              'pass_fit_imgA': X_sc_train,\n",
    "          },\n",
    "          validation_data=(\n",
    "              {'input_img': X_sc_test, 'input_cls': y_cat_test},\n",
    "              {\n",
    "                  'pass_cls_img': X_sc_test,\n",
    "                  'pass_fit_imgA': X_sc_test,\n",
    "              }\n",
    "          ),\n",
    "          verbose=0,\n",
    "          batch_size=32,\n",
    "          epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit({'input_img': X_sc_train, 'input_cls': y_cat_train},\n",
    "          {\n",
    "              'pass_cls_img': X_sc_train,\n",
    "              'pass_fit_imgA': X_sc_train,\n",
    "          },\n",
    "          validation_data=(\n",
    "              {'input_img': X_sc_test, 'input_cls': y_cat_test},\n",
    "              {\n",
    "                  'pass_cls_img': X_sc_test,\n",
    "                  'pass_fit_imgA': X_sc_test,\n",
    "              }\n",
    "          ),\n",
    "          verbose=0,\n",
    "          batch_size=32,\n",
    "          epochs=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### img > associated img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_img = models['model_img_img'].predict({'input_img': X_sc, 'input_cls': y_cat}, batch_size=32, verbose=1)\n",
    "print(pred_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows=2\n",
    "ncols=10\n",
    "fig, subs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(10, 3))\n",
    "\n",
    "for jj in range(ncols):\n",
    "    iplt = subs[0, jj]\n",
    "    img_array = X_sc[jj].reshape((8,8))\n",
    "    iplt.imshow(img_array)\n",
    "    iplt = subs[1, jj]\n",
    "    img_array = pred_img[jj].reshape((8,8))\n",
    "    iplt.imshow(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows=2\n",
    "ncols=10\n",
    "fig, subs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(10, 3))\n",
    "\n",
    "for jj in range(ncols):\n",
    "    iplt = subs[0, jj]\n",
    "    img_array = X_sc[jj+20].reshape((8,8))\n",
    "    iplt.imshow(img_array)\n",
    "    iplt = subs[1, jj]\n",
    "    img_array = pred_img[jj].reshape((8,8))\n",
    "    iplt.imshow(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "print(y[idx])\n",
    "fig, subs = plt.subplots(nrows=1, ncols=2)\n",
    "subs[0].imshow(X_sc[idx].reshape((8,8)))\n",
    "subs[1].imshow(pred_img[idx].reshape((8,8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### abstract images of digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_img = models['model_cls_img'].predict({'input_img': X_sc, 'input_cls': y_cat}, batch_size=32, verbose=1)\n",
    "print(pred_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows=1\n",
    "ncols=10\n",
    "fig, subs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(10, 3))\n",
    "\n",
    "for jj in range(ncols):\n",
    "    iplt = subs[jj]\n",
    "    img_array = pred_img[jj].reshape((8,8))\n",
    "    iplt.imshow(img_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot weights of embed layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgt_dense = models['model_embed'].get_layer('embed').get_weights()[0]\n",
    "#wgt_dense = 1 / (1 + np.exp(-wgt_dense))\n",
    "print(wgt_dense.shape)\n",
    "\n",
    "nrows=1\n",
    "ncols=10\n",
    "fig, subs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(10, 5))\n",
    "\n",
    "for ii in range(nrows):\n",
    "    for jj in range(ncols):\n",
    "        iplt = subs[jj]\n",
    "        img_array = wgt_dense[jj].reshape((8,8))\n",
    "        iplt.imshow(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_img = models['model_img_img'].predict({'input_img': wgt_dense}, batch_size=32, verbose=1)\n",
    "print(pred_img.shape)\n",
    "\n",
    "nrows=1\n",
    "ncols=10\n",
    "fig, subs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(10, 5))\n",
    "\n",
    "for ii in range(nrows):\n",
    "    for jj in range(ncols):\n",
    "        iplt = subs[jj]\n",
    "        img_array = pred_img[jj].reshape((8,8))\n",
    "        iplt.imshow(img_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot output of model_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ae_embed = models['model_embed'].predict(y_cat)\n",
    "pred_ae_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows=1\n",
    "ncols=10\n",
    "fig, subs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(10, 5))\n",
    "\n",
    "for ii in range(nrows):\n",
    "    for jj in range(ncols):\n",
    "        iplt = subs[jj]\n",
    "        img_array = pred_ae_embed[jj].reshape((8,8))\n",
    "        iplt.imshow(img_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot output of GaussianKernel layer #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_imgA_train = models['model_img_img'].predict({'input_img': X_sc_train}, batch_size=32, verbose=1)\n",
    "print(pred_imgA_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gk1_pred = models['model_gk1'].predict({'input_img': pred_imgA_train}, batch_size=32, verbose=1)\n",
    "df = pd.DataFrame(gk1_pred[:,:5])\n",
    "df['cls'] = ['c'+str(ee) for ee in y_train]\n",
    "sns.pairplot(df, markers='.', hue='cls', size=2.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(gk1_pred[:,50:55])\n",
    "df['cls'] = ['c'+str(ee) for ee in y_train]\n",
    "sns.pairplot(df, markers='.', hue='cls', size=2.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgt = models['model_img_img'].get_layer('gkernel1').get_weights()[0]\n",
    "wgt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(wgt[:,:5])\n",
    "sns.pairplot(df, markers='.', size=2.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(wgt[:,50:55])\n",
    "sns.pairplot(df, markers='.', size=2.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(wgt[0].reshape((8,8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 10\n",
    "ncols = num_lm0\n",
    "fig, subs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15, 10))\n",
    "\n",
    "for ii in range(nrows):\n",
    "    for jj in range(ncols):\n",
    "        iplt = subs[ii,jj]\n",
    "        img_array = wgt[ii*ncols+jj].reshape((8, 8))\n",
    "        iplt.imshow(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
