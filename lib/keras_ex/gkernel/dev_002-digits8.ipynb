{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os, sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, make_scorer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras import regularizers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('/home/admin/github/wordroid.sblo.jp/lib/keras_ex')\n",
    "#from gkernel import GaussianKernel, GaussianKernel2, GaussianKernel3\n",
    "from gkernel.sklearn import RBFClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1797, 64), 0.0, 1.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "X = X / 16\n",
    "X.shape, X.min(), X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = y.shape[0]\n",
    "y2 = keras.utils.to_categorical(y, num_classes=10)\n",
    "y2.shape\n",
    "index = np.arange(N)\n",
    "xtrain = X[index[index % 2 != 0],:]\n",
    "ytrain = y2[index[index % 2 != 0]]\n",
    "xtest = X[index[index % 2 == 0],:]\n",
    "yans = y2[index[index % 2 == 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import copy\n",
    "\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "# from keras.callbacks import EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "# from keras.optimizers import RMSprop, Adam\n",
    "# from keras.initializers import glorot_uniform\n",
    "# from keras.models import Sequential\n",
    "\n",
    "\n",
    "\n",
    "# def make_model_gkernel1(\n",
    "#     nn=4, num_lm=2,\n",
    "#     random_state=None, lm=None, gamma=None):\n",
    "#     '''\n",
    "#     just activation\n",
    "#     '''\n",
    "#     inp = Input(shape=(nn,), name='inp')\n",
    "#     oup = inp\n",
    "    \n",
    "#     if lm is None:\n",
    "#         rs = np.random.RandomState(random_state)\n",
    "#         lm = rs.random_sample((num_lm, nn))\n",
    "#     if gamma is None:\n",
    "#         gamma = 1/(2*np.sqrt(nn/6)*2)\n",
    "#     weights = [np.log(np.array([gamma]))]\n",
    "#     oup = GaussianKernel2(lm, weights=weights, name='gkernel', trainable=False)(oup)\n",
    "    \n",
    "#     model = Model(inp, oup, name='model_gkernel')\n",
    "#     return lm, model\n",
    "\n",
    "# def make_model_gkernel2(\n",
    "#     nn=4, num_lm=2,\n",
    "#     random_state=None, lm=None, gamma=None):\n",
    "    \n",
    "#     inp = Input(shape=(nn,), name='inp')\n",
    "#     oup = inp\n",
    "    \n",
    "#     if lm is None:\n",
    "#         rs = np.random.RandomState(random_state)\n",
    "#         lm = rs.random_sample((num_lm, nn))\n",
    "#     if gamma is None:\n",
    "#         gamma = 1/(2*np.sqrt(nn/6)*2)\n",
    "#     weights = [np.log(np.array([gamma]))]\n",
    "#     #weights = [np.array([gamma])]\n",
    "#     oup = GaussianKernel2(lm, weights=weights, name='gkernel')(oup)\n",
    "    \n",
    "#     model = Model(inp, oup, name='model_gkernel')\n",
    "#     return lm, model\n",
    "\n",
    "# def make_model_gkernel3(\n",
    "#     nn=4, num_lm=2,\n",
    "#     random_state=None, lm=None, gamma=None):\n",
    "\n",
    "#     inp = Input(shape=(nn,), name='inp')\n",
    "#     oup = inp\n",
    "    \n",
    "#     if lm is None:\n",
    "#         rs = np.random.RandomState(random_state)\n",
    "#         lm = rs.random_sample((num_lm, nn))\n",
    "#     if gamma is None:\n",
    "#         gamma = 1/(2*np.sqrt(nn/6)*2)\n",
    "#     weights = [lm, np.log(np.array([gamma]))]\n",
    "#     oup = GaussianKernel3(num_landmark=num_lm, num_feature=nn, weights=weights, name='gkernel')(oup)\n",
    "    \n",
    "#     model = Model(inp, oup, name='model_gkernel')\n",
    "#     return lm, model\n",
    "\n",
    "# def make_model_out(\n",
    "#     num_lm=2, num_cls=3,\n",
    "#     activation='softmax',\n",
    "#     reg_l1=0.0, reg_l2=0.0,\n",
    "#     random_state=None\n",
    "# ):\n",
    "#     inp = Input(shape=(num_lm,), name='inp')\n",
    "#     oup = Dense(num_cls,\n",
    "#                 activation=activation,\n",
    "#                 kernel_initializer=glorot_uniform(random_state),\n",
    "#                 kernel_regularizer=regularizers.l1_l2(reg_l1, reg_l2),\n",
    "#                 bias_regularizer=regularizers.l1_l2(reg_l1, reg_l2)\n",
    "#                )(inp)\n",
    "    \n",
    "#     model = Model(inp, oup, name='model_out')\n",
    "#     return model\n",
    "\n",
    "# def make_model(\n",
    "#     make_model_gkernel=make_model_gkernel2,\n",
    "#     make_model_out=make_model_out,\n",
    "#     reg_l1=0.0, reg_l2=0.0,\n",
    "#     nn=2,\n",
    "#     num_lm=2, lm=None, gamma=None,\n",
    "#     random_state=None,\n",
    "#     num_cls=2, activation='softmax',\n",
    "#     opt=0.02, lr=0.02,\n",
    "#     loss='categorical_crossentropy',\n",
    "#     session_clear=True,\n",
    "#     #gkernel_multipliers=1.0,\n",
    "#     lm_select_from_x=None,\n",
    "#     tol=None\n",
    "# ):\n",
    "#     if session_clear:\n",
    "#         K.clear_session()\n",
    "    \n",
    "#     lm, model_gkernel = make_model_gkernel(\n",
    "#         nn=nn, num_lm=num_lm,\n",
    "#         random_state=random_state, lm=lm, gamma=gamma\n",
    "#     )\n",
    "#     model_out = make_model_out(\n",
    "#         num_lm=num_lm, num_cls=num_cls,\n",
    "#         activation=activation,\n",
    "#         reg_l1=reg_l1, reg_l2=reg_l2,\n",
    "#         random_state=random_state\n",
    "#     )\n",
    "#     #model_gkernel.summary()\n",
    "#     #model_out.summary()\n",
    "    \n",
    "#     inp = model_gkernel.inputs[0]\n",
    "#     oup = model_gkernel(inp)\n",
    "#     oup = model_out(oup)\n",
    "    \n",
    "#     model = Model(inp, oup)\n",
    "#     #model.summary()\n",
    "# #     if isinstance(opt, float):\n",
    "# #         opt = Adam(opt)\n",
    "# #     learning_rate_multipliers = {\n",
    "# #         'gkernel': gkernel_multipliers,\n",
    "# #     }\n",
    "# #     print(learning_rate_multipliers)\n",
    "# #     opt = Adam_lr_mult(\n",
    "# #         lr,\n",
    "# #         multipliers=learning_rate_multipliers,\n",
    "# #         debug_verbose=False)\n",
    "#     opt = Adam(lr)\n",
    "#     model.compile(optimizer=opt, loss=loss, metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "\n",
    "# class RBFBase(object):\n",
    "    \n",
    "#     def _fit(self, x, y, sample_weight=None, **kwargs):\n",
    "#         sk_params_org = copy.deepcopy(self.sk_params)\n",
    "        \n",
    "#         ### nn\n",
    "#         nn = x.shape[1]\n",
    "#         sk_params_org.update({'nn': self.sk_params.get('nn')})\n",
    "#         self.set_params(nn=nn)\n",
    "        \n",
    "#         ### learning_rate\n",
    "#         if self.sk_params.get('lr') is None:\n",
    "#             lr = 0.02 # default lr\n",
    "#             sk_params_org.update({'lr': None})\n",
    "#             self.set_params(lr=lr)\n",
    "#         else:\n",
    "#             lr = self.sk_params['lr'] # for later using\n",
    "        \n",
    "#         ### gamma\n",
    "#         if self.sk_params.get('gamma') == 'scale':\n",
    "#             sk_params_org.update({'gamma': 'scale'})\n",
    "#             self.set_params(gamma=1 / (nn * x.var()))\n",
    "#             #print('scale gamma >', self.sk_params['gamma'])\n",
    "        \n",
    "#         ### tol\n",
    "#         tol = self.sk_params.get('tol', np.finfo(np.float32).eps)\n",
    "        \n",
    "#         ### callbacks\n",
    "#         if self.sk_params.get('callbacks', None) is None:\n",
    "#             lr_reducer = ReduceLROnPlateau(monitor='loss', \n",
    "#                                factor=1/2,\n",
    "#                                verbose=0,\n",
    "#                                cooldown=7,\n",
    "#                                patience=5,\n",
    "#                                min_lr=lr/64/2)\n",
    "#             #tol = np.sqrt(np.finfo(np.float32).eps)\n",
    "#             #tol = np.finfo(np.float32).eps\n",
    "#             #tol = 0.0\n",
    "#             early_stopping = EarlyStopping(monitor='loss', patience=5, min_delta=tol, restore_best_weights=True)\n",
    "#             callbacks0 = [lr_reducer, early_stopping]\n",
    "#             callbacks = [lr_reducer, early_stopping]\n",
    "#             sk_params_org.update({'callbacks': None})\n",
    "#             self.set_params(callbacks=callbacks)\n",
    "#         else:\n",
    "#             callbacks0 = self.sk_params['callbacks']\n",
    "#             callbacks = self.sk_params['callbacks']\n",
    "        \n",
    "#         ### lm_select_from_x\n",
    "#         #print('''self.sk_params.get('lm_select_from_x') >''', self.sk_params.get('lm_select_from_x'))\n",
    "#         if self.sk_params.get('lm_select_from_x'):\n",
    "#             random_state = self.sk_params.get('random_state')\n",
    "#             rs = np.random.RandomState(random_state)\n",
    "#             lm = x[rs.choice(np.arange(x.shape[0]), self.sk_params['num_lm'], replace=False)]\n",
    "#             sk_params_org.update({'lm': self.sk_params.get('lm')})\n",
    "#             self.set_params(lm=lm)\n",
    "        \n",
    "#         hst = super().fit(x, y, **kwargs)\n",
    "        \n",
    "#         fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n",
    "#         fit_args.update(kwargs)\n",
    "        \n",
    "#         def lr_schedule2(epoch):\n",
    "#             lr1 = lr / 2\n",
    "#             #print('lr >', lr1)\n",
    "#             return lr1\n",
    "#         def lr_schedule4(epoch):\n",
    "#             lr1 = lr / 4\n",
    "#             #print('lr >', lr1)\n",
    "#             return lr1\n",
    "#         def lr_schedule8(epoch):\n",
    "#             lr1 = lr / 8\n",
    "#             #print('lr >', lr1)\n",
    "#             return lr1\n",
    "        \n",
    "#         # 2\n",
    "#         lr_scheduler = LearningRateScheduler(lr_schedule2)\n",
    "#         callbacks = callbacks0 + [lr_scheduler]\n",
    "#         fit_args['callbacks'] = callbacks\n",
    "#         hst = self.model.fit(x, y, **fit_args)\n",
    "#         # 3\n",
    "#         lr_scheduler = LearningRateScheduler(lr_schedule4)\n",
    "#         callbacks = callbacks0 + [lr_scheduler]\n",
    "#         fit_args['callbacks'] = callbacks\n",
    "#         hst = self.model.fit(x, y, **fit_args)\n",
    "#         # 4\n",
    "#         lr_scheduler = LearningRateScheduler(lr_schedule8)\n",
    "#         callbacks = callbacks0 + [lr_scheduler]\n",
    "#         fit_args['callbacks'] = callbacks\n",
    "#         hst = self.model.fit(x, y, **fit_args)\n",
    "        \n",
    "#         # 2\n",
    "#         lr_scheduler = LearningRateScheduler(lr_schedule2)\n",
    "#         callbacks = callbacks0 + [lr_scheduler]\n",
    "#         fit_args['callbacks'] = callbacks\n",
    "#         hst = self.model.fit(x, y, **fit_args)\n",
    "#         # 3\n",
    "#         lr_scheduler = LearningRateScheduler(lr_schedule4)\n",
    "#         callbacks = callbacks0 + [lr_scheduler]\n",
    "#         fit_args['callbacks'] = callbacks\n",
    "#         hst = self.model.fit(x, y, **fit_args)\n",
    "#         # 4\n",
    "#         lr_scheduler = LearningRateScheduler(lr_schedule8)\n",
    "#         callbacks = callbacks0 + [lr_scheduler]\n",
    "#         fit_args['callbacks'] = callbacks\n",
    "#         hst = self.model.fit(x, y, **fit_args)\n",
    "        \n",
    "#         #print(self.sk_params)\n",
    "#         #print(sk_params_org)\n",
    "#         self.set_params(**sk_params_org)\n",
    "#         #print(self.sk_params)\n",
    "#         return hst\n",
    "    \n",
    "#     def current_gamma(self):\n",
    "#         for ew in self.model.layers[1].layers[1].get_weights():\n",
    "#             if len(ew.shape)==1:\n",
    "#                 c_gamma = ew[0]\n",
    "#         return np.exp(c_gamma)\n",
    "\n",
    "\n",
    "# class RBFClassifier(RBFBase, KerasClassifier):\n",
    "    \n",
    "#     def __init__(self, build_fn=make_model, **sk_params):\n",
    "#         super().__init__(build_fn, **sk_params)\n",
    "    \n",
    "#     def fit(self, x, y, sample_weight=None, **kwargs):\n",
    "#         ### num_cls\n",
    "#         self.set_params(num_cls=self.sk_params.get('num_cls', y.shape[1]))\n",
    "#         hst = super()._fit(x, y, sample_weight=None, **kwargs)\n",
    "#         return hst\n",
    "\n",
    "# class RBFRegressor(RBFBase, KerasRegressor):\n",
    "    \n",
    "#     def __init__(self, build_fn=make_model, **sk_params):\n",
    "#         super().__init__(build_fn, **sk_params)\n",
    "    \n",
    "#     def fit(self, x, y, sample_weight=None, **kwargs):\n",
    "#         ### num_cls\n",
    "#         self.set_params(num_cls=self.sk_params.get('num_cls', 1))\n",
    "        \n",
    "#         ### activation\n",
    "#         self.set_params(activation=self.sk_params.get('activation', 'linear'))\n",
    "        \n",
    "#         ### loss\n",
    "#         self.set_params(loss=self.sk_params.get('loss', 'mse'))\n",
    "        \n",
    "#         hst = super()._fit(x, y, sample_weight=None, **kwargs)\n",
    "#         return hst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gkernel.sklearn.RBFClassifier at 0x7ff4aecbf2b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clf = RBFClassifier(num_lm=3)\n",
    "# clf = RBFClassifier(\n",
    "#     num_lm=3,\n",
    "#     lm=xtrain[:3]\n",
    "# )\n",
    "# clf = RBFClassifier(\n",
    "#     num_lm=50,\n",
    "#     lm=xtrain[:50],\n",
    "#     make_model_gkernel=make_model_gkernel3\n",
    "# )\n",
    "# early_stopping = EarlyStopping(monitor='loss', patience=5, min_delta=0.000, restore_best_weights=True)\n",
    "# clf = RBFClassifier(\n",
    "#     num_lm=3,\n",
    "#     lm=xtrain[np.random.choice(np.arange(xtrain.shape[0]), 3)],\n",
    "# )\n",
    "# clf = RBFClassifier(\n",
    "#     num_lm=10,\n",
    "#     lm=xtrain[:10],\n",
    "#     callbacks=[early_stopping],\n",
    "#     make_model_gkernel=make_model_gkernel3\n",
    "# )\n",
    "# clf = RBFClassifier(\n",
    "#     num_lm=3,\n",
    "#     lm=xtrain[:3],\n",
    "#     make_model_gkernel=make_model_gkernel3,\n",
    "#     activation='sigmoid',\n",
    "#     loss='binary_crossentropy'\n",
    "# )\n",
    "clf = RBFClassifier(\n",
    "    num_lm=10,\n",
    "    lm=xtrain[np.random.choice(np.arange(xtrain.shape[0]), 10)],\n",
    "    reg_l1=0.00,\n",
    "    lr=0.02,\n",
    "    random_state=101\n",
    ")\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0923 23:44:19.782620 140690256598848 deprecation_wrapper.py:119] From /home/admin/miniconda3/envs/da02/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "W0923 23:44:19.785177 140690256598848 deprecation_wrapper.py:119] From /home/admin/miniconda3/envs/da02/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0923 23:44:19.796476 140690256598848 deprecation_wrapper.py:119] From /home/admin/miniconda3/envs/da02/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0923 23:44:19.797162 140690256598848 deprecation_wrapper.py:119] From /home/admin/miniconda3/envs/da02/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0923 23:44:19.798604 140690256598848 deprecation_wrapper.py:119] From /home/admin/miniconda3/envs/da02/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0923 23:44:19.889058 140690256598848 deprecation_wrapper.py:119] From /home/admin/miniconda3/envs/da02/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0923 23:44:19.961726 140690256598848 deprecation.py:323] From /home/admin/miniconda3/envs/da02/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.5 s, sys: 590 ms, total: 18.1 s\n",
      "Wall time: 12.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff4aeca5eb8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf.fit(xtrain, ytrain, epochs=500, batch_size=1024, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'callbacks': None,\n",
       " 'lm': array([[0.    , 0.    , 0.1875, 0.75  , 0.9375, 0.6875, 0.125 , 0.    ,\n",
       "         0.    , 0.    , 0.6875, 0.8125, 0.4375, 0.8125, 0.5   , 0.    ,\n",
       "         0.    , 0.4375, 0.9375, 0.0625, 0.3125, 0.9375, 0.1875, 0.    ,\n",
       "         0.    , 0.0625, 0.75  , 1.    , 1.    , 0.3125, 0.    , 0.    ,\n",
       "         0.    , 0.    , 0.    , 0.8125, 0.9375, 0.9375, 0.125 , 0.    ,\n",
       "         0.    , 0.    , 0.125 , 0.8125, 0.    , 0.625 , 0.3125, 0.    ,\n",
       "         0.    , 0.    , 0.25  , 0.6875, 0.25  , 0.6875, 0.375 , 0.    ,\n",
       "         0.    , 0.    , 0.125 , 0.8125, 1.    , 0.75  , 0.    , 0.    ],\n",
       "        [0.    , 0.    , 0.3125, 0.9375, 0.4375, 0.    , 0.    , 0.    ,\n",
       "         0.    , 0.    , 0.875 , 1.    , 1.    , 0.3125, 0.    , 0.    ,\n",
       "         0.    , 0.    , 0.8125, 0.875 , 0.875 , 0.9375, 0.    , 0.    ,\n",
       "         0.    , 0.    , 0.1875, 0.6875, 0.875 , 1.    , 0.1875, 0.    ,\n",
       "         0.    , 0.    , 0.    , 0.    , 0.375 , 1.    , 0.125 , 0.    ,\n",
       "         0.    , 0.    , 0.    , 0.    , 0.25  , 1.    , 0.4375, 0.    ,\n",
       "         0.    , 0.    , 0.    , 0.0625, 0.6875, 1.    , 0.375 , 0.    ,\n",
       "         0.    , 0.    , 0.25  , 0.9375, 1.    , 0.625 , 0.    , 0.    ],\n",
       "        [0.    , 0.    , 0.5625, 1.    , 0.6875, 0.0625, 0.    , 0.    ,\n",
       "         0.    , 0.3125, 1.    , 0.625 , 1.    , 0.5625, 0.    , 0.    ,\n",
       "         0.    , 0.375 , 0.875 , 0.0625, 0.5625, 0.9375, 0.    , 0.    ,\n",
       "         0.    , 0.0625, 0.9375, 0.375 , 0.6875, 1.    , 0.125 , 0.    ,\n",
       "         0.    , 0.    , 0.4375, 1.    , 0.9375, 1.    , 0.4375, 0.    ,\n",
       "         0.    , 0.    , 0.    , 0.1875, 0.0625, 0.6875, 0.5625, 0.    ,\n",
       "         0.    , 0.1875, 0.875 , 0.5625, 0.5625, 0.875 , 0.75  , 0.    ,\n",
       "         0.    , 0.    , 0.75  , 1.    , 1.    , 0.8125, 0.1875, 0.    ],\n",
       "        [0.    , 0.    , 0.6875, 0.75  , 0.    , 0.    , 0.    , 0.    ,\n",
       "         0.    , 0.125 , 1.    , 1.    , 1.    , 0.8125, 0.    , 0.    ,\n",
       "         0.    , 0.1875, 1.    , 0.75  , 0.625 , 0.875 , 0.    , 0.    ,\n",
       "         0.    , 0.0625, 1.    , 0.0625, 0.75  , 0.9375, 0.    , 0.    ,\n",
       "         0.    , 0.    , 0.8125, 1.    , 0.5625, 0.9375, 0.125 , 0.    ,\n",
       "         0.    , 0.    , 0.    , 0.1875, 0.    , 0.5625, 0.6875, 0.    ,\n",
       "         0.    , 0.    , 0.    , 0.    , 0.5625, 0.9375, 0.25  , 0.    ,\n",
       "         0.    , 0.    , 0.5625, 0.75  , 0.8125, 0.1875, 0.    , 0.    ],\n",
       "        [0.    , 0.    , 0.375 , 1.    , 0.8125, 0.75  , 0.875 , 0.0625,\n",
       "         0.    , 0.    , 0.875 , 0.25  , 0.25  , 0.9375, 0.25  , 0.    ,\n",
       "         0.    , 0.0625, 0.4375, 0.    , 0.625 , 0.4375, 0.    , 0.    ,\n",
       "         0.    , 0.    , 0.    , 0.125 , 0.8125, 0.0625, 0.    , 0.    ,\n",
       "         0.    , 0.125 , 0.5625, 0.875 , 1.    , 0.75  , 0.    , 0.    ,\n",
       "         0.    , 0.25  , 0.375 , 0.9375, 0.125 , 0.25  , 0.0625, 0.    ,\n",
       "         0.    , 0.    , 0.375 , 0.4375, 0.    , 0.    , 0.    , 0.    ,\n",
       "         0.    , 0.    , 0.625 , 0.25  , 0.    , 0.    , 0.    , 0.    ],\n",
       "        [0.    , 0.    , 0.0625, 0.75  , 0.75  , 0.25  , 0.0625, 0.    ,\n",
       "         0.    , 0.    , 0.8125, 0.8125, 0.8125, 0.875 , 0.5   , 0.    ,\n",
       "         0.    , 0.375 , 0.9375, 0.    , 0.    , 0.75  , 0.4375, 0.    ,\n",
       "         0.    , 0.125 , 1.    , 0.8125, 0.75  , 0.8125, 0.0625, 0.    ,\n",
       "         0.    , 0.    , 0.    , 0.875 , 1.    , 0.5625, 0.    , 0.    ,\n",
       "         0.    , 0.    , 0.375 , 0.625 , 0.125 , 1.    , 0.    , 0.    ,\n",
       "         0.    , 0.    , 0.6875, 0.5   , 0.3125, 1.    , 0.    , 0.    ,\n",
       "         0.    , 0.    , 0.1875, 0.75  , 1.    , 0.4375, 0.    , 0.    ],\n",
       "        [0.    , 0.    , 0.6875, 1.    , 0.4375, 0.    , 0.    , 0.    ,\n",
       "         0.    , 0.0625, 1.    , 0.6875, 0.9375, 0.    , 0.    , 0.    ,\n",
       "         0.    , 0.125 , 1.    , 0.3125, 1.    , 0.25  , 0.    , 0.    ,\n",
       "         0.    , 0.    , 0.125 , 0.125 , 1.    , 0.1875, 0.    , 0.    ,\n",
       "         0.    , 0.    , 0.    , 0.3125, 1.    , 0.    , 0.    , 0.    ,\n",
       "         0.    , 0.    , 0.    , 0.5625, 0.875 , 0.    , 0.    , 0.    ,\n",
       "         0.    , 0.    , 0.5625, 1.    , 0.875 , 0.4375, 0.375 , 0.    ,\n",
       "         0.    , 0.    , 0.8125, 0.875 , 0.875 , 1.    , 1.    , 0.375 ],\n",
       "        [0.    , 0.    , 0.4375, 1.    , 1.    , 0.875 , 0.    , 0.    ,\n",
       "         0.    , 0.    , 1.    , 0.75  , 0.625 , 0.9375, 0.0625, 0.    ,\n",
       "         0.    , 0.    , 0.625 , 0.25  , 1.    , 0.625 , 0.    , 0.    ,\n",
       "         0.    , 0.    , 0.    , 0.5625, 1.    , 0.6875, 0.0625, 0.    ,\n",
       "         0.    , 0.    , 0.    , 0.    , 0.4375, 1.    , 0.5   , 0.    ,\n",
       "         0.    , 0.    , 0.    , 0.    , 0.    , 1.    , 0.4375, 0.    ,\n",
       "         0.    , 0.    , 0.5   , 0.25  , 0.625 , 0.9375, 0.125 , 0.    ,\n",
       "         0.    , 0.    , 0.75  , 1.    , 1.    , 0.375 , 0.    , 0.    ],\n",
       "        [0.    , 0.    , 0.625 , 1.    , 1.    , 0.5   , 0.    , 0.    ,\n",
       "         0.    , 0.    , 0.3125, 0.5   , 0.8125, 0.8125, 0.    , 0.    ,\n",
       "         0.    , 0.    , 0.    , 0.    , 0.5625, 0.8125, 0.    , 0.    ,\n",
       "         0.    , 0.    , 0.    , 0.125 , 0.8125, 0.75  , 0.    , 0.    ,\n",
       "         0.    , 0.    , 0.125 , 0.9375, 1.    , 1.    , 0.4375, 0.    ,\n",
       "         0.    , 0.    , 0.    , 0.8125, 0.8125, 0.3125, 0.0625, 0.    ,\n",
       "         0.    , 0.    , 0.0625, 0.875 , 0.3125, 0.    , 0.    , 0.    ,\n",
       "         0.    , 0.    , 0.5625, 0.8125, 0.0625, 0.    , 0.    , 0.    ],\n",
       "        [0.    , 0.    , 0.125 , 0.9375, 0.9375, 0.1875, 0.    , 0.    ,\n",
       "         0.    , 0.    , 0.5   , 0.875 , 1.    , 0.6875, 0.    , 0.    ,\n",
       "         0.    , 0.    , 0.    , 0.    , 0.6875, 0.875 , 0.    , 0.    ,\n",
       "         0.    , 0.    , 0.    , 0.    , 0.6875, 0.875 , 0.1875, 0.    ,\n",
       "         0.    , 0.    , 0.25  , 0.75  , 1.    , 1.    , 0.4375, 0.    ,\n",
       "         0.    , 0.    , 0.6875, 1.    , 0.75  , 0.0625, 0.    , 0.    ,\n",
       "         0.    , 0.    , 0.0625, 0.875 , 0.375 , 0.    , 0.    , 0.    ,\n",
       "         0.    , 0.    , 0.25  , 0.75  , 0.0625, 0.    , 0.    , 0.    ]]),\n",
       " 'lr': 0.02,\n",
       " 'nn': None,\n",
       " 'num_cls': 10,\n",
       " 'num_lm': 10,\n",
       " 'random_state': 101,\n",
       " 'reg_l1': 0.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.sk_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'build_fn': <function gkernel.sklearn.make_model>,\n",
       " 'classes_': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'model': <keras.engine.training.Model at 0x7ff4ae9cb898>,\n",
       " 'n_classes_': 10,\n",
       " 'sk_params': {'callbacks': None,\n",
       "  'lm': array([[0.    , 0.    , 0.1875, 0.75  , 0.9375, 0.6875, 0.125 , 0.    ,\n",
       "          0.    , 0.    , 0.6875, 0.8125, 0.4375, 0.8125, 0.5   , 0.    ,\n",
       "          0.    , 0.4375, 0.9375, 0.0625, 0.3125, 0.9375, 0.1875, 0.    ,\n",
       "          0.    , 0.0625, 0.75  , 1.    , 1.    , 0.3125, 0.    , 0.    ,\n",
       "          0.    , 0.    , 0.    , 0.8125, 0.9375, 0.9375, 0.125 , 0.    ,\n",
       "          0.    , 0.    , 0.125 , 0.8125, 0.    , 0.625 , 0.3125, 0.    ,\n",
       "          0.    , 0.    , 0.25  , 0.6875, 0.25  , 0.6875, 0.375 , 0.    ,\n",
       "          0.    , 0.    , 0.125 , 0.8125, 1.    , 0.75  , 0.    , 0.    ],\n",
       "         [0.    , 0.    , 0.3125, 0.9375, 0.4375, 0.    , 0.    , 0.    ,\n",
       "          0.    , 0.    , 0.875 , 1.    , 1.    , 0.3125, 0.    , 0.    ,\n",
       "          0.    , 0.    , 0.8125, 0.875 , 0.875 , 0.9375, 0.    , 0.    ,\n",
       "          0.    , 0.    , 0.1875, 0.6875, 0.875 , 1.    , 0.1875, 0.    ,\n",
       "          0.    , 0.    , 0.    , 0.    , 0.375 , 1.    , 0.125 , 0.    ,\n",
       "          0.    , 0.    , 0.    , 0.    , 0.25  , 1.    , 0.4375, 0.    ,\n",
       "          0.    , 0.    , 0.    , 0.0625, 0.6875, 1.    , 0.375 , 0.    ,\n",
       "          0.    , 0.    , 0.25  , 0.9375, 1.    , 0.625 , 0.    , 0.    ],\n",
       "         [0.    , 0.    , 0.5625, 1.    , 0.6875, 0.0625, 0.    , 0.    ,\n",
       "          0.    , 0.3125, 1.    , 0.625 , 1.    , 0.5625, 0.    , 0.    ,\n",
       "          0.    , 0.375 , 0.875 , 0.0625, 0.5625, 0.9375, 0.    , 0.    ,\n",
       "          0.    , 0.0625, 0.9375, 0.375 , 0.6875, 1.    , 0.125 , 0.    ,\n",
       "          0.    , 0.    , 0.4375, 1.    , 0.9375, 1.    , 0.4375, 0.    ,\n",
       "          0.    , 0.    , 0.    , 0.1875, 0.0625, 0.6875, 0.5625, 0.    ,\n",
       "          0.    , 0.1875, 0.875 , 0.5625, 0.5625, 0.875 , 0.75  , 0.    ,\n",
       "          0.    , 0.    , 0.75  , 1.    , 1.    , 0.8125, 0.1875, 0.    ],\n",
       "         [0.    , 0.    , 0.6875, 0.75  , 0.    , 0.    , 0.    , 0.    ,\n",
       "          0.    , 0.125 , 1.    , 1.    , 1.    , 0.8125, 0.    , 0.    ,\n",
       "          0.    , 0.1875, 1.    , 0.75  , 0.625 , 0.875 , 0.    , 0.    ,\n",
       "          0.    , 0.0625, 1.    , 0.0625, 0.75  , 0.9375, 0.    , 0.    ,\n",
       "          0.    , 0.    , 0.8125, 1.    , 0.5625, 0.9375, 0.125 , 0.    ,\n",
       "          0.    , 0.    , 0.    , 0.1875, 0.    , 0.5625, 0.6875, 0.    ,\n",
       "          0.    , 0.    , 0.    , 0.    , 0.5625, 0.9375, 0.25  , 0.    ,\n",
       "          0.    , 0.    , 0.5625, 0.75  , 0.8125, 0.1875, 0.    , 0.    ],\n",
       "         [0.    , 0.    , 0.375 , 1.    , 0.8125, 0.75  , 0.875 , 0.0625,\n",
       "          0.    , 0.    , 0.875 , 0.25  , 0.25  , 0.9375, 0.25  , 0.    ,\n",
       "          0.    , 0.0625, 0.4375, 0.    , 0.625 , 0.4375, 0.    , 0.    ,\n",
       "          0.    , 0.    , 0.    , 0.125 , 0.8125, 0.0625, 0.    , 0.    ,\n",
       "          0.    , 0.125 , 0.5625, 0.875 , 1.    , 0.75  , 0.    , 0.    ,\n",
       "          0.    , 0.25  , 0.375 , 0.9375, 0.125 , 0.25  , 0.0625, 0.    ,\n",
       "          0.    , 0.    , 0.375 , 0.4375, 0.    , 0.    , 0.    , 0.    ,\n",
       "          0.    , 0.    , 0.625 , 0.25  , 0.    , 0.    , 0.    , 0.    ],\n",
       "         [0.    , 0.    , 0.0625, 0.75  , 0.75  , 0.25  , 0.0625, 0.    ,\n",
       "          0.    , 0.    , 0.8125, 0.8125, 0.8125, 0.875 , 0.5   , 0.    ,\n",
       "          0.    , 0.375 , 0.9375, 0.    , 0.    , 0.75  , 0.4375, 0.    ,\n",
       "          0.    , 0.125 , 1.    , 0.8125, 0.75  , 0.8125, 0.0625, 0.    ,\n",
       "          0.    , 0.    , 0.    , 0.875 , 1.    , 0.5625, 0.    , 0.    ,\n",
       "          0.    , 0.    , 0.375 , 0.625 , 0.125 , 1.    , 0.    , 0.    ,\n",
       "          0.    , 0.    , 0.6875, 0.5   , 0.3125, 1.    , 0.    , 0.    ,\n",
       "          0.    , 0.    , 0.1875, 0.75  , 1.    , 0.4375, 0.    , 0.    ],\n",
       "         [0.    , 0.    , 0.6875, 1.    , 0.4375, 0.    , 0.    , 0.    ,\n",
       "          0.    , 0.0625, 1.    , 0.6875, 0.9375, 0.    , 0.    , 0.    ,\n",
       "          0.    , 0.125 , 1.    , 0.3125, 1.    , 0.25  , 0.    , 0.    ,\n",
       "          0.    , 0.    , 0.125 , 0.125 , 1.    , 0.1875, 0.    , 0.    ,\n",
       "          0.    , 0.    , 0.    , 0.3125, 1.    , 0.    , 0.    , 0.    ,\n",
       "          0.    , 0.    , 0.    , 0.5625, 0.875 , 0.    , 0.    , 0.    ,\n",
       "          0.    , 0.    , 0.5625, 1.    , 0.875 , 0.4375, 0.375 , 0.    ,\n",
       "          0.    , 0.    , 0.8125, 0.875 , 0.875 , 1.    , 1.    , 0.375 ],\n",
       "         [0.    , 0.    , 0.4375, 1.    , 1.    , 0.875 , 0.    , 0.    ,\n",
       "          0.    , 0.    , 1.    , 0.75  , 0.625 , 0.9375, 0.0625, 0.    ,\n",
       "          0.    , 0.    , 0.625 , 0.25  , 1.    , 0.625 , 0.    , 0.    ,\n",
       "          0.    , 0.    , 0.    , 0.5625, 1.    , 0.6875, 0.0625, 0.    ,\n",
       "          0.    , 0.    , 0.    , 0.    , 0.4375, 1.    , 0.5   , 0.    ,\n",
       "          0.    , 0.    , 0.    , 0.    , 0.    , 1.    , 0.4375, 0.    ,\n",
       "          0.    , 0.    , 0.5   , 0.25  , 0.625 , 0.9375, 0.125 , 0.    ,\n",
       "          0.    , 0.    , 0.75  , 1.    , 1.    , 0.375 , 0.    , 0.    ],\n",
       "         [0.    , 0.    , 0.625 , 1.    , 1.    , 0.5   , 0.    , 0.    ,\n",
       "          0.    , 0.    , 0.3125, 0.5   , 0.8125, 0.8125, 0.    , 0.    ,\n",
       "          0.    , 0.    , 0.    , 0.    , 0.5625, 0.8125, 0.    , 0.    ,\n",
       "          0.    , 0.    , 0.    , 0.125 , 0.8125, 0.75  , 0.    , 0.    ,\n",
       "          0.    , 0.    , 0.125 , 0.9375, 1.    , 1.    , 0.4375, 0.    ,\n",
       "          0.    , 0.    , 0.    , 0.8125, 0.8125, 0.3125, 0.0625, 0.    ,\n",
       "          0.    , 0.    , 0.0625, 0.875 , 0.3125, 0.    , 0.    , 0.    ,\n",
       "          0.    , 0.    , 0.5625, 0.8125, 0.0625, 0.    , 0.    , 0.    ],\n",
       "         [0.    , 0.    , 0.125 , 0.9375, 0.9375, 0.1875, 0.    , 0.    ,\n",
       "          0.    , 0.    , 0.5   , 0.875 , 1.    , 0.6875, 0.    , 0.    ,\n",
       "          0.    , 0.    , 0.    , 0.    , 0.6875, 0.875 , 0.    , 0.    ,\n",
       "          0.    , 0.    , 0.    , 0.    , 0.6875, 0.875 , 0.1875, 0.    ,\n",
       "          0.    , 0.    , 0.25  , 0.75  , 1.    , 1.    , 0.4375, 0.    ,\n",
       "          0.    , 0.    , 0.6875, 1.    , 0.75  , 0.0625, 0.    , 0.    ,\n",
       "          0.    , 0.    , 0.0625, 0.875 , 0.375 , 0.    , 0.    , 0.    ,\n",
       "          0.    , 0.    , 0.25  , 0.75  , 0.0625, 0.    , 0.    , 0.    ]]),\n",
       "  'lr': 0.02,\n",
       "  'nn': None,\n",
       "  'num_cls': 10,\n",
       "  'num_lm': 10,\n",
       "  'random_state': 101,\n",
       "  'reg_l1': 0.0}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11427088"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.current_gamma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 9, 7, 9, 1, 3, 5, 7, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(xtrain)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.24190164e-01, 1.42645047e-04, 5.75913989e-04, 1.50571548e-04,\n",
       "        1.44329737e-03, 2.99103837e-02, 1.16840657e-03, 3.04540823e-04,\n",
       "        2.29085907e-02, 1.92053895e-02],\n",
       "       [8.69081449e-03, 4.71826971e-01, 2.45093137e-01, 4.95541748e-03,\n",
       "        4.26684767e-02, 2.19757911e-02, 6.00259006e-02, 1.60581637e-02,\n",
       "        1.22767545e-01, 5.93775697e-03],\n",
       "       [2.63670292e-02, 1.08059786e-01, 9.55783413e-04, 2.99776566e-05,\n",
       "        8.40935111e-01, 1.59446197e-03, 9.59259830e-03, 9.84997302e-03,\n",
       "        5.24596893e-04, 2.09072116e-03],\n",
       "       [2.58982200e-02, 1.87338889e-01, 1.46568129e-02, 2.60843808e-04,\n",
       "        5.11527285e-02, 2.96568405e-02, 6.30047977e-01, 4.53077839e-04,\n",
       "        5.39223216e-02, 6.61234511e-03],\n",
       "       [1.61991298e-01, 1.46336318e-03, 6.00928580e-03, 2.72217859e-03,\n",
       "        5.05853619e-04, 1.20629249e-02, 2.60793362e-02, 9.98455798e-05,\n",
       "        6.71686947e-01, 1.17379002e-01]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(xtest)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "898/898 [==============================] - 0s 144us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8262806236080178"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "899/899 [==============================] - 0s 25us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8453837597993378"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(xtest, yans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_SCORE : 0.8248791607415862\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92        88\n",
      "           1       0.76      0.73      0.75        89\n",
      "           2       0.87      0.79      0.83        91\n",
      "           3       0.86      0.87      0.87        93\n",
      "           4       0.85      0.95      0.90        88\n",
      "           5       0.76      0.84      0.80        91\n",
      "           6       0.87      0.91      0.89        90\n",
      "           7       0.88      0.89      0.89        91\n",
      "           8       0.70      0.66      0.68        86\n",
      "           9       0.76      0.71      0.73        91\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       898\n",
      "   macro avg       0.83      0.83      0.82       898\n",
      "weighted avg       0.83      0.83      0.83       898\n",
      "\n",
      "[[79  1  0  0  2  5  1  0  0  0]\n",
      " [ 0 65  6  0  4  1  2  3  1  7]\n",
      " [ 0  4 72  3  1  2  2  2  5  0]\n",
      " [ 1  0  1 81  0  1  0  3  3  3]\n",
      " [ 0  1  0  0 84  0  0  2  1  0]\n",
      " [ 1  3  1  0  0 76  2  0  4  4]\n",
      " [ 0  4  0  0  0  1 82  0  1  2]\n",
      " [ 0  1  0  0  7  0  0 81  1  1]\n",
      " [ 2  4  2  2  0 12  2  1 57  4]\n",
      " [ 0  2  1  8  1  2  3  0  9 65]]\n"
     ]
    }
   ],
   "source": [
    "print('F1_SCORE :', f1_score(np.argmax(ytrain,axis=1), clf.predict(xtrain), average='macro'))\n",
    "print(classification_report(np.argmax(ytrain,axis=1), clf.predict(xtrain)))\n",
    "print(confusion_matrix(np.argmax(ytrain,axis=1), clf.predict(xtrain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_SCORE : 0.8450998576273658\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96        90\n",
      "           1       0.77      0.80      0.78        93\n",
      "           2       0.93      0.90      0.91        86\n",
      "           3       0.81      0.88      0.84        90\n",
      "           4       0.90      0.91      0.91        93\n",
      "           5       0.80      0.78      0.79        91\n",
      "           6       0.90      0.91      0.91        91\n",
      "           7       0.89      0.91      0.90        88\n",
      "           8       0.76      0.72      0.74        88\n",
      "           9       0.72      0.71      0.72        89\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       899\n",
      "   macro avg       0.85      0.85      0.85       899\n",
      "weighted avg       0.85      0.85      0.85       899\n",
      "\n",
      "[[85  0  0  0  0  2  2  0  1  0]\n",
      " [ 1 74  4  0  4  1  4  0  3  2]\n",
      " [ 0  3 77  1  0  0  0  1  4  0]\n",
      " [ 0  0  1 79  0  1  0  3  1  5]\n",
      " [ 0  2  0  0 85  1  0  4  1  0]\n",
      " [ 1  2  0  1  1 71  1  0  3 11]\n",
      " [ 1  4  0  0  0  0 83  0  3  0]\n",
      " [ 0  1  0  1  3  0  0 80  3  0]\n",
      " [ 0  5  1  1  1  7  2  2 63  6]\n",
      " [ 0  5  0 14  0  6  0  0  1 63]]\n"
     ]
    }
   ],
   "source": [
    "print('F1_SCORE :', f1_score(np.argmax(yans,axis=1), clf.predict(xtest), average='macro'))\n",
    "print(classification_report(np.argmax(yans,axis=1), clf.predict(xtest)))\n",
    "print(confusion_matrix(np.argmax(yans,axis=1), clf.predict(xtest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV, validation_curve\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, roc_auc_score, r2_score, make_scorer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counter  | val_f1    |  val_r2    \n",
      "---------------------------------------------\n",
      "    0    |  0.4204   |  -0.6106   1.235459e-01 <-- OK  \n",
      "    1    |  0.4088   |  -0.4615   1.182230e-01 <-- OK  \n",
      "    2    |  0.4203   |  -0.6536   1.144033e-01 <-- OK  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/miniconda3/envs/da02/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    3    |  0.4060   |  -0.1983   1.103966e-01 <-- OK  \n",
      "    4    |  0.3204   |  -0.1793   1.206005e-01 <-- OK  \n",
      "    5    |  0.3872   |  -0.3883   1.433272e-01 <-- OK  \n",
      "    6    |  0.4030   |  -0.1596   1.009572e-01 <-- OK  \n",
      "    7    |  0.3930   |  -0.3983   1.222785e-01 <-- OK  \n",
      "    8    |  0.4056   |  -0.3601   1.385151e-01 <-- OK  \n",
      "    9    |  0.3152   |  -0.6620   1.058504e-01 <-- OK  \n",
      "   10    |  0.3768   |  -0.2431   1.353818e-01 <-- OK  \n",
      "   11    |  0.3448   |  -0.5477   1.331684e-01 <-- OK  \n",
      "   12    |  0.4403   |  -0.3226   1.129881e-01 <-- OK  \n",
      "   13    |  0.3788   |  -0.2013   1.025722e-01 <-- OK  \n",
      "   14    |  0.4283   |  -0.5616   1.377715e-01 <-- OK  \n",
      "   15    |  0.3029   |  -0.5757   8.906122e-02 <-- OK  \n",
      "   16    |  0.3731   |  -0.1813   1.065135e-01 <-- OK  \n",
      "   17    |  0.3541   |  -0.6318   1.498295e-01 <-- OK  \n",
      "   18    |  0.4011   |  -0.3450   1.099304e-01 <-- OK  \n",
      "   19    |  0.4713   |  -0.1160   1.080779e-01 <-- OK  \n",
      "   20    |  0.4403   |  -0.3110   1.219129e-01 <-- OK  \n",
      "   21    |  0.4642   |  -0.3354   1.146874e-01 <-- OK  \n",
      "   22    |  0.4130   |  -0.2446   1.113633e-01 <-- OK  \n",
      "   23    |  0.3636   |  -0.1160   1.259237e-01 <-- OK  \n",
      "   24    |  0.4100   |  -0.1518   1.305409e-01 <-- OK  \n",
      "   25    |  0.4030   |  -0.1442   1.273957e-01 <-- OK  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/miniconda3/envs/da02/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   26    |  0.2669   |  -0.6829   1.491105e-01 <-- skipping  \n",
      "   27    |  0.3932   |  -0.3414   1.126856e-01 <-- OK  \n",
      "   28    |  0.4488   |  -0.0592   1.300201e-01 <-- OK  \n",
      "   29    |  0.4271   |  -0.0990   1.296547e-01 <-- OK  \n",
      "   30    |  0.5106   |  0.1255   1.257863e-01 <-- OK  \n",
      "   31    |  0.3827   |  -0.4586   1.447242e-01 <-- OK  \n",
      "   32    |  0.4013   |  -0.0531   9.644230e-02 <-- OK  \n",
      "   33    |  0.3848   |  -0.4468   1.133118e-01 <-- OK  \n",
      "   34    |  0.4135   |  -0.6089   1.059621e-01 <-- OK  \n",
      "   35    |  0.4821   |  0.0972   1.196165e-01 <-- OK  \n",
      "   36    |  0.3906   |  -0.3569   1.422569e-01 <-- OK  \n",
      "   37    |  0.3753   |  -0.3227   1.238176e-01 <-- OK  \n",
      "   38    |  0.3598   |  -0.3098   9.428260e-02 <-- OK  \n",
      "   39    |  0.3225   |  -0.6177   9.484406e-02 <-- OK  \n",
      "   40    |  0.4030   |  -0.2968   1.222501e-01 <-- OK  \n",
      "   41    |  0.3359   |  -0.5366   1.240893e-01 <-- OK  \n",
      "   42    |  0.3869   |  -0.4119   1.177511e-01 <-- OK  \n",
      "   43    |  0.3588   |  -0.6153   1.233508e-01 <-- OK  \n",
      "   44    |  0.3979   |  -0.4453   1.070839e-01 <-- OK  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/miniconda3/envs/da02/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   45    |  0.3813   |  -0.2248   1.231836e-01 <-- OK  \n",
      "   46    |  0.3647   |  -0.3749   1.284760e-01 <-- OK  \n",
      "   47    |  0.3845   |  -0.7125   1.313143e-01 <-- OK  \n",
      "   48    |  0.3871   |  -0.5191   1.506562e-01 <-- OK  \n",
      "   49    |  0.4854   |  0.0609   1.263022e-01 <-- OK  \n",
      "CPU times: user 12min 5s, sys: 22.9 s, total: 12min 27s\n",
      "Wall time: 8min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ins_splitter = StratifiedShuffleSplit(n_splits=50, test_size=0.5, random_state=0)\n",
    "var_idx_all = np.arange(xtrain.shape[1])\n",
    "#threshold = 0.85\n",
    "threshold = 0.30\n",
    "importances = np.zeros((xtrain.shape[1],))\n",
    "predictions = pd.DataFrame()\n",
    "#preds_all = pd.DataFrame()\n",
    "pred_all_list = []\n",
    "pred_train_all_list = []\n",
    "counter = 0\n",
    "np.random.seed(10001)\n",
    "\n",
    "print(\"counter  | val_f1    |  val_r2    \")\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "\n",
    "for train_index, val_index in ins_splitter.split(xtrain, ytrain):\n",
    "    x_train_tr, x_train_val = xtrain[train_index], xtrain[val_index]\n",
    "    y_train_tr, y_train_val = ytrain[train_index], ytrain[val_index]\n",
    "    \n",
    "    \n",
    "    #estimator = LGBMRegressor(min_child_samples=50, reg_alpha=100)\n",
    "    estimator = RBFClassifier(\n",
    "        num_lm=2,\n",
    "        lm_select_from_x=True,\n",
    "        random_state=None,\n",
    "        lr=0.02, gamma='scale',\n",
    "        epochs=500, batch_size=1024, verbose=0\n",
    "    )\n",
    "    estimator.fit(x_train_tr, y_train_tr)\n",
    "    \n",
    "    # score our fitted model on validation data\n",
    "    val_y_pred = estimator.predict(x_train_val)\n",
    "    val_mse = mean_squared_error(np.argmax(y_train_val,axis=1), val_y_pred)\n",
    "    val_mae = mean_absolute_error(np.argmax(y_train_val,axis=1), val_y_pred)\n",
    "    val_kappa = 0.0\n",
    "    val_f1 = f1_score(np.argmax(y_train_val,axis=1), val_y_pred, average='macro')\n",
    "    val_cos = cosine_similarity(np.argmax(y_train_val,axis=1).reshape(1, -1), val_y_pred.reshape(1, -1))[0][0]\n",
    "    val_dst = euclidean_distances(np.argmax(y_train_val,axis=1).reshape(1, -1), val_y_pred.reshape(1, -1))[0][0]\n",
    "    val_r2  = r2_score(np.argmax(y_train_val,axis=1), val_y_pred)\n",
    "    gamma = estimator.current_gamma()\n",
    "    \n",
    "    if val_f1 > threshold:\n",
    "        message = '<-- OK'\n",
    "        pred_train_all = estimator.predict_proba(xtrain)\n",
    "        pred_train_all_list.append(pred_train_all)\n",
    "        pred_all = estimator.predict_proba(xtest)\n",
    "        pred_all_list.append(pred_all)\n",
    "        #preds_all = pd.concat([preds_all, pd.DataFrame(pred_all)], axis=1)\n",
    "        #prediction = grid_search.best_estimator_.predict(x_test0)\n",
    "        #predictions = pd.concat([predictions, pd.DataFrame(prediction)], axis=1)\n",
    "        #importances += estimator.feature_importances_\n",
    "        #filename = 'model-{}.sav'.format(counter)\n",
    "        #joblib.dump(estimator, filename)\n",
    "    else:\n",
    "        message = '<-- skipping'\n",
    "\n",
    "    print(\"{0:5}    |  {3:.4f}   |  {4:.4f}   {5:5e} {7}  \".format(\n",
    "        counter,\n",
    "        val_mse,\n",
    "        val_mae,\n",
    "        val_f1,\n",
    "        val_r2,\n",
    "        gamma,\n",
    "        0,\n",
    "        message))\n",
    "    \n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_SCORE : 0.4406541654186345\n",
      "F1_SCORE : 0.40382556210984094\n",
      "F1_SCORE : 0.4289029587954074\n",
      "F1_SCORE : 0.37143901258116674\n",
      "F1_SCORE : 0.3451013460337898\n",
      "F1_SCORE : 0.3781137288610215\n",
      "F1_SCORE : 0.41809227501234536\n",
      "F1_SCORE : 0.4109717799143865\n",
      "F1_SCORE : 0.4156301865411013\n",
      "F1_SCORE : 0.31348167485810374\n",
      "F1_SCORE : 0.4035436519207666\n",
      "F1_SCORE : 0.36313971959248087\n",
      "F1_SCORE : 0.44060550260464987\n",
      "F1_SCORE : 0.3757763654354628\n",
      "F1_SCORE : 0.4300674638790711\n",
      "F1_SCORE : 0.3157810695123784\n",
      "F1_SCORE : 0.3897017805204272\n",
      "F1_SCORE : 0.36422907916676855\n",
      "F1_SCORE : 0.39088406487111904\n",
      "F1_SCORE : 0.4727710350961768\n",
      "F1_SCORE : 0.4369394420024625\n",
      "F1_SCORE : 0.46231307745810446\n",
      "F1_SCORE : 0.40456716817038085\n",
      "F1_SCORE : 0.3463540985484071\n",
      "F1_SCORE : 0.42277340326467006\n",
      "F1_SCORE : 0.42101145251645294\n",
      "F1_SCORE : 0.3987467168035996\n",
      "F1_SCORE : 0.46502425312257606\n",
      "F1_SCORE : 0.4268926394578427\n",
      "F1_SCORE : 0.5129131457314077\n",
      "F1_SCORE : 0.3759248399832348\n",
      "F1_SCORE : 0.4259226081912919\n",
      "F1_SCORE : 0.3768133480026104\n",
      "F1_SCORE : 0.4236857816529761\n",
      "F1_SCORE : 0.48539453629989404\n",
      "F1_SCORE : 0.3701344957681376\n",
      "F1_SCORE : 0.4071136802176\n",
      "F1_SCORE : 0.3635434827239208\n",
      "F1_SCORE : 0.33435759782617047\n",
      "F1_SCORE : 0.4041953453943088\n",
      "F1_SCORE : 0.3191984982414846\n",
      "F1_SCORE : 0.426621230202979\n",
      "F1_SCORE : 0.34239196658034304\n",
      "F1_SCORE : 0.4112678207141232\n",
      "F1_SCORE : 0.3840823784542882\n",
      "F1_SCORE : 0.359732248530105\n",
      "F1_SCORE : 0.4123678602469079\n",
      "F1_SCORE : 0.3788326434871625\n",
      "F1_SCORE : 0.49675668104322523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/miniconda3/envs/da02/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for ee in pred_train_all_list:\n",
    "    print('F1_SCORE :', f1_score(np.argmax(ytrain, axis=1), np.argmax(ee, axis=1), average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_SCORE : 0.8645262684606015\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97        88\n",
      "           1       0.89      0.85      0.87        89\n",
      "           2       0.87      0.82      0.85        91\n",
      "           3       0.81      0.87      0.84        93\n",
      "           4       0.83      0.97      0.89        88\n",
      "           5       0.92      0.76      0.83        91\n",
      "           6       0.97      0.99      0.98        90\n",
      "           7       0.82      0.98      0.89        91\n",
      "           8       0.91      0.71      0.80        86\n",
      "           9       0.70      0.75      0.72        91\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       898\n",
      "   macro avg       0.87      0.87      0.86       898\n",
      "weighted avg       0.87      0.87      0.86       898\n",
      "\n",
      "[[84  0  0  0  2  0  2  0  0  0]\n",
      " [ 0 76  5  0  1  0  1  0  0  6]\n",
      " [ 1  1 75  6  3  0  0  2  3  0]\n",
      " [ 0  0  2 81  0  1  0  4  0  5]\n",
      " [ 0  0  0  0 85  0  0  3  0  0]\n",
      " [ 1  0  0  3  2 69  0  3  2 11]\n",
      " [ 0  1  0  0  0  0 89  0  0  0]\n",
      " [ 0  0  0  0  2  0  0 89  0  0]\n",
      " [ 0  6  4  3  1  4  0  0 61  7]\n",
      " [ 0  1  0  7  6  1  0  7  1 68]]\n"
     ]
    }
   ],
   "source": [
    "print('F1_SCORE :', f1_score(np.argmax(ytrain, axis=1), np.argmax(np.stack(pred_train_all_list).mean(axis=0), axis=1), average='macro'))\n",
    "print(classification_report(np.argmax(ytrain, axis=1), np.argmax(np.stack(pred_train_all_list).mean(axis=0), axis=1)))\n",
    "print(confusion_matrix(np.argmax(ytrain, axis=1), np.argmax(np.stack(pred_train_all_list).mean(axis=0), axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(899, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(pred_all_list).mean(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_SCORE : 0.44997031015879624\n",
      "F1_SCORE : 0.4243263455121663\n",
      "F1_SCORE : 0.41583134051168774\n",
      "F1_SCORE : 0.3692130605959628\n",
      "F1_SCORE : 0.3314889111615035\n",
      "F1_SCORE : 0.3933025556137534\n",
      "F1_SCORE : 0.3886387882885815\n",
      "F1_SCORE : 0.40810043902014803\n",
      "F1_SCORE : 0.43286137595582935\n",
      "F1_SCORE : 0.32195295574428734\n",
      "F1_SCORE : 0.4044382641315557\n",
      "F1_SCORE : 0.3707030017908365\n",
      "F1_SCORE : 0.4522835489079161\n",
      "F1_SCORE : 0.37072128318755276\n",
      "F1_SCORE : 0.46361398312893504\n",
      "F1_SCORE : 0.35038227452794773\n",
      "F1_SCORE : 0.42130516306406296\n",
      "F1_SCORE : 0.3744701164078785\n",
      "F1_SCORE : 0.40153766865750595\n",
      "F1_SCORE : 0.49975508481551423\n",
      "F1_SCORE : 0.3882238773082986\n",
      "F1_SCORE : 0.455455067162578\n",
      "F1_SCORE : 0.3795611399600135\n",
      "F1_SCORE : 0.39961149526832884\n",
      "F1_SCORE : 0.35834112910698396\n",
      "F1_SCORE : 0.4212040734016905\n",
      "F1_SCORE : 0.3976923810296032\n",
      "F1_SCORE : 0.45604738390351585\n",
      "F1_SCORE : 0.43695179831241837\n",
      "F1_SCORE : 0.5111000756557869\n",
      "F1_SCORE : 0.3572610929181027\n",
      "F1_SCORE : 0.41396458024183946\n",
      "F1_SCORE : 0.3505172316438331\n",
      "F1_SCORE : 0.418681979337856\n",
      "F1_SCORE : 0.4697210293356752\n",
      "F1_SCORE : 0.3762922982002646\n",
      "F1_SCORE : 0.41701919775202245\n",
      "F1_SCORE : 0.3637203168987553\n",
      "F1_SCORE : 0.3300536546336377\n",
      "F1_SCORE : 0.4191360793836302\n",
      "F1_SCORE : 0.33865759165987713\n",
      "F1_SCORE : 0.4236600726441188\n",
      "F1_SCORE : 0.3169418919196004\n",
      "F1_SCORE : 0.4138111526936578\n",
      "F1_SCORE : 0.36285317710285464\n",
      "F1_SCORE : 0.37649363609886377\n",
      "F1_SCORE : 0.3984922659373541\n",
      "F1_SCORE : 0.3130994956980756\n",
      "F1_SCORE : 0.48671629793792687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/miniconda3/envs/da02/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for ee in pred_all_list:\n",
    "    print('F1_SCORE :', f1_score(np.argmax(yans, axis=1), np.argmax(ee, axis=1), average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_SCORE : 0.8826660371568613\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        90\n",
      "           1       0.88      0.78      0.83        93\n",
      "           2       0.87      0.88      0.88        86\n",
      "           3       0.87      0.86      0.86        90\n",
      "           4       0.91      0.92      0.92        93\n",
      "           5       0.95      0.76      0.84        91\n",
      "           6       0.95      0.99      0.97        91\n",
      "           7       0.82      0.98      0.89        88\n",
      "           8       0.89      0.84      0.87        88\n",
      "           9       0.73      0.82      0.77        89\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       899\n",
      "   macro avg       0.89      0.88      0.88       899\n",
      "weighted avg       0.89      0.88      0.88       899\n",
      "\n",
      "[[90  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 73  7  0  3  0  5  0  0  5]\n",
      " [ 0  2 76  2  1  0  0  0  3  2]\n",
      " [ 0  0  1 77  0  0  0  4  5  3]\n",
      " [ 0  1  0  0 86  0  0  6  0  0]\n",
      " [ 0  0  0  3  2 69  0  2  1 14]\n",
      " [ 0  0  0  0  1  0 90  0  0  0]\n",
      " [ 0  0  1  0  0  0  0 86  0  1]\n",
      " [ 0  7  2  1  0  1  0  1 74  2]\n",
      " [ 0  0  0  6  1  3  0  6  0 73]]\n"
     ]
    }
   ],
   "source": [
    "print('F1_SCORE :', f1_score(np.argmax(yans, axis=1), np.argmax(np.stack(pred_all_list).mean(axis=0), axis=1), average='macro'))\n",
    "print(classification_report(np.argmax(yans, axis=1), np.argmax(np.stack(pred_all_list).mean(axis=0), axis=1)))\n",
    "print(confusion_matrix(np.argmax(yans, axis=1), np.argmax(np.stack(pred_all_list).mean(axis=0), axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation_curve + LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_splitter = StratifiedShuffleSplit(n_splits=3, test_size=0.35, random_state=0)\n",
    "cv_splitter.get_n_splits(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_name = \"C\"\n",
    "param_range = np.logspace(-3, 3, 7)\n",
    "param_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1_scorer(estimator, X, y):\n",
    "    pred = estimator.predict(X)\n",
    "    s = f1_score(y, pred, average='macro')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=0.001 .........................................................\n",
      "[CV] .......................................... C=0.001, total=   0.0s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] ........................................... C=0.01, total=   0.1s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................................ C=0.1, total=   3.2s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ............................................ C=1.0, total=   9.4s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] ........................................... C=10.0, total=  41.6s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] .......................................... C=100.0, total= 1.2min\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ......................................... C=1000.0, total= 1.1min\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] .......................................... C=0.001, total=   0.0s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] ........................................... C=0.01, total=   0.1s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................................ C=0.1, total=   1.8s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ............................................ C=1.0, total=   9.1s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] ........................................... C=10.0, total=  34.4s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] .......................................... C=100.0, total= 1.2min\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ......................................... C=1000.0, total= 1.1min\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] .......................................... C=0.001, total=   0.0s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] ........................................... C=0.01, total=   0.1s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................................ C=0.1, total=   3.3s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ............................................ C=1.0, total=   8.8s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] ........................................... C=10.0, total=  42.8s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] .......................................... C=100.0, total= 1.3min\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ......................................... C=1000.0, total= 1.2min\n",
      "CPU times: user 9min 42s, sys: 0 ns, total: 9min 42s\n",
      "Wall time: 9min 41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:  9.7min finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_scores, test_scores = validation_curve(\n",
    "    LogisticRegression(penalty='l1', multi_class='multinomial', solver='saga', max_iter=10000),\n",
    "    np.hstack(pred_train_all_list), np.argmax(ytrain, axis=1),\n",
    "    param_name=param_name, param_range=param_range,\n",
    "    cv=cv_splitter, n_jobs=1, verbose=2, scoring=f1_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e-03, 1.83800623e-02, 1.82688944e-02],\n",
       "       [1.00000000e-02, 1.81908749e-02, 1.82688944e-02],\n",
       "       [1.00000000e-01, 8.82685922e-01, 8.51054622e-01],\n",
       "       [1.00000000e+00, 9.65075150e-01, 9.00063108e-01],\n",
       "       [1.00000000e+01, 1.00000000e+00, 9.36120626e-01],\n",
       "       [1.00000000e+02, 1.00000000e+00, 9.47683157e-01],\n",
       "       [1.00000000e+03, 1.00000000e+00, 9.49787209e-01]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "np.c_[param_range, train_scores_mean, test_scores_mean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff4804ca4a8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEaCAYAAAD+E0veAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff4805dba90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Validation Curve\")\n",
    "plt.xlabel(\"param\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=10000, multi_class='multinomial',\n",
       "          n_jobs=None, penalty='l1', random_state=None, solver='saga',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''test data'''\n",
    "est = LogisticRegression(penalty='l1', multi_class='multinomial', solver='saga', max_iter=10000, C=1000)\n",
    "est.fit(np.hstack(pred_train_all_list), np.argmax(ytrain, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = est.predict(np.hstack(pred_train_all_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_SCORE : 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        88\n",
      "           1       1.00      1.00      1.00        89\n",
      "           2       1.00      1.00      1.00        91\n",
      "           3       1.00      1.00      1.00        93\n",
      "           4       1.00      1.00      1.00        88\n",
      "           5       1.00      1.00      1.00        91\n",
      "           6       1.00      1.00      1.00        90\n",
      "           7       1.00      1.00      1.00        91\n",
      "           8       1.00      1.00      1.00        86\n",
      "           9       1.00      1.00      1.00        91\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       898\n",
      "   macro avg       1.00      1.00      1.00       898\n",
      "weighted avg       1.00      1.00      1.00       898\n",
      "\n",
      "[[88  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 89  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 91  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 93  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 88  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 91  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 90  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 91  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 86  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 91]]\n"
     ]
    }
   ],
   "source": [
    "print('F1_SCORE :', f1_score(np.argmax(ytrain, axis=1), pred, average='macro'))\n",
    "print(classification_report(np.argmax(ytrain, axis=1), pred))\n",
    "print(confusion_matrix(np.argmax(ytrain, axis=1), pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_test = est.predict(np.hstack(pred_all_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_SCORE : 0.9699530110220188\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        90\n",
      "           1       0.97      0.96      0.96        93\n",
      "           2       0.99      1.00      0.99        86\n",
      "           3       0.95      0.98      0.96        90\n",
      "           4       0.99      0.99      0.99        93\n",
      "           5       0.98      0.95      0.96        91\n",
      "           6       1.00      0.98      0.99        91\n",
      "           7       0.97      0.98      0.97        88\n",
      "           8       0.94      0.94      0.94        88\n",
      "           9       0.93      0.94      0.94        89\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       899\n",
      "   macro avg       0.97      0.97      0.97       899\n",
      "weighted avg       0.97      0.97      0.97       899\n",
      "\n",
      "[[89  0  1  0  0  0  0  0  0  0]\n",
      " [ 0 89  0  0  0  1  0  0  2  1]\n",
      " [ 0  0 86  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 88  0  0  0  1  1  0]\n",
      " [ 0  0  0  0 92  0  0  1  0  0]\n",
      " [ 0  0  0  1  1 86  0  0  1  2]\n",
      " [ 1  0  0  0  0  0 89  0  1  0]\n",
      " [ 0  0  0  1  0  0  0 86  0  1]\n",
      " [ 0  2  0  0  0  0  0  1 83  2]\n",
      " [ 0  1  0  3  0  1  0  0  0 84]]\n"
     ]
    }
   ],
   "source": [
    "print('F1_SCORE :', f1_score(np.argmax(yans, axis=1), pred_test, average='macro'))\n",
    "print(classification_report(np.argmax(yans, axis=1), pred_test))\n",
    "print(confusion_matrix(np.argmax(yans, axis=1), pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation_curve + LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''LGBMClassifier'''\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "param_name = \"reg_alpha\"\n",
    "param_range = np.logspace(-3, 3, 7)\n",
    "param_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] reg_alpha=0.001 .................................................\n",
      "[CV] .................................. reg_alpha=0.001, total=   0.3s\n",
      "[CV] reg_alpha=0.01 ..................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................... reg_alpha=0.01, total=   0.3s\n",
      "[CV] reg_alpha=0.1 ...................................................\n",
      "[CV] .................................... reg_alpha=0.1, total=   0.3s\n",
      "[CV] reg_alpha=1.0 ...................................................\n",
      "[CV] .................................... reg_alpha=1.0, total=   0.2s\n",
      "[CV] reg_alpha=10.0 ..................................................\n",
      "[CV] ................................... reg_alpha=10.0, total=   0.2s\n",
      "[CV] reg_alpha=100.0 .................................................\n",
      "[CV] .................................. reg_alpha=100.0, total=   0.1s\n",
      "[CV] reg_alpha=1000.0 ................................................\n",
      "[CV] ................................. reg_alpha=1000.0, total=   0.1s\n",
      "[CV] reg_alpha=0.001 .................................................\n",
      "[CV] .................................. reg_alpha=0.001, total=   0.3s\n",
      "[CV] reg_alpha=0.01 ..................................................\n",
      "[CV] ................................... reg_alpha=0.01, total=   0.3s\n",
      "[CV] reg_alpha=0.1 ...................................................\n",
      "[CV] .................................... reg_alpha=0.1, total=   0.2s\n",
      "[CV] reg_alpha=1.0 ...................................................\n",
      "[CV] .................................... reg_alpha=1.0, total=   0.2s\n",
      "[CV] reg_alpha=10.0 ..................................................\n",
      "[CV] ................................... reg_alpha=10.0, total=   0.2s\n",
      "[CV] reg_alpha=100.0 .................................................\n",
      "[CV] .................................. reg_alpha=100.0, total=   0.1s\n",
      "[CV] reg_alpha=1000.0 ................................................\n",
      "[CV] ................................. reg_alpha=1000.0, total=   0.1s\n",
      "[CV] reg_alpha=0.001 .................................................\n",
      "[CV] .................................. reg_alpha=0.001, total=   0.3s\n",
      "[CV] reg_alpha=0.01 ..................................................\n",
      "[CV] ................................... reg_alpha=0.01, total=   0.3s\n",
      "[CV] reg_alpha=0.1 ...................................................\n",
      "[CV] .................................... reg_alpha=0.1, total=   0.3s\n",
      "[CV] reg_alpha=1.0 ...................................................\n",
      "[CV] .................................... reg_alpha=1.0, total=   0.2s\n",
      "[CV] reg_alpha=10.0 ..................................................\n",
      "[CV] ................................... reg_alpha=10.0, total=   0.2s\n",
      "[CV] reg_alpha=100.0 .................................................\n",
      "[CV] .................................. reg_alpha=100.0, total=   0.1s\n",
      "[CV] reg_alpha=1000.0 ................................................\n",
      "[CV] ................................. reg_alpha=1000.0, total=   0.1s\n",
      "CPU times: user 4.09 s, sys: 0 ns, total: 4.09 s\n",
      "Wall time: 4.42 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:    4.4s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_scores, test_scores = validation_curve(\n",
    "    LGBMClassifier(\n",
    "        min_child_samples=50,\n",
    "        reg_alpha=0.1\n",
    "    ),\n",
    "    np.hstack(pred_train_all_list), np.argmax(ytrain, axis=1),\n",
    "    param_name=param_name, param_range=param_range,\n",
    "    cv=cv_splitter, n_jobs=1, verbose=2, scoring=f1_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e-03, 9.50422580e-01, 8.66096647e-01],\n",
       "       [1.00000000e-02, 9.51001885e-01, 8.65083273e-01],\n",
       "       [1.00000000e-01, 9.50409128e-01, 8.65083273e-01],\n",
       "       [1.00000000e+00, 9.52720781e-01, 8.58514058e-01],\n",
       "       [1.00000000e+01, 9.32318695e-01, 8.53500481e-01],\n",
       "       [1.00000000e+02, 1.78125000e-02, 1.79190751e-02],\n",
       "       [1.00000000e+03, 1.78125000e-02, 1.79190751e-02]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "np.c_[param_range, train_scores_mean, test_scores_mean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff4ac0ad160>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEaCAYAAAD+E0veAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlUzq0njJAQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff4a42a6710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Validation Curve\")\n",
    "plt.xlabel(\"param\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=1, learning_rate=0.1,\n",
       "        max_bin=255, max_depth=-1, min_child_samples=50,\n",
       "        min_child_weight=5, min_split_gain=0, n_estimators=10, nthread=-1,\n",
       "        num_leaves=31, objective='multiclass', reg_alpha=0.01,\n",
       "        reg_lambda=0, seed=0, silent=True, subsample=1,\n",
       "        subsample_for_bin=50000, subsample_freq=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''test data'''\n",
    "est = LGBMClassifier(\n",
    "        min_child_samples=50,\n",
    "        reg_alpha=0.01\n",
    "    )\n",
    "est.fit(np.hstack(pred_train_all_list), np.argmax(ytrain, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = est.predict(np.hstack(pred_train_all_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_SCORE : 0.9587593096847016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        88\n",
      "           1       0.94      0.98      0.96        89\n",
      "           2       0.97      0.97      0.97        91\n",
      "           3       0.99      0.92      0.96        93\n",
      "           4       0.99      0.98      0.98        88\n",
      "           5       0.95      0.96      0.95        91\n",
      "           6       0.94      0.99      0.96        90\n",
      "           7       0.93      0.99      0.96        91\n",
      "           8       0.95      0.91      0.93        86\n",
      "           9       0.96      0.93      0.94        91\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       898\n",
      "   macro avg       0.96      0.96      0.96       898\n",
      "weighted avg       0.96      0.96      0.96       898\n",
      "\n",
      "[[85  0  0  0  1  0  2  0  0  0]\n",
      " [ 0 87  0  0  0  0  2  0  0  0]\n",
      " [ 0  0 88  1  0  0  0  1  1  0]\n",
      " [ 0  0  1 86  0  2  0  1  1  2]\n",
      " [ 0  0  0  0 86  0  0  2  0  0]\n",
      " [ 0  0  1  0  0 87  1  0  0  2]\n",
      " [ 0  1  0  0  0  0 89  0  0  0]\n",
      " [ 0  1  0  0  0  0  0 90  0  0]\n",
      " [ 0  3  1  0  0  3  1  0 78  0]\n",
      " [ 0  1  0  0  0  0  0  3  2 85]]\n"
     ]
    }
   ],
   "source": [
    "print('F1_SCORE :', f1_score(np.argmax(ytrain, axis=1), pred, average='macro'))\n",
    "print(classification_report(np.argmax(ytrain, axis=1), pred))\n",
    "print(confusion_matrix(np.argmax(ytrain, axis=1), pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_test = est.predict(np.hstack(pred_all_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_SCORE : 0.9206284167301575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        90\n",
      "           1       0.92      0.83      0.87        93\n",
      "           2       0.89      0.94      0.92        86\n",
      "           3       0.92      0.88      0.90        90\n",
      "           4       0.98      0.95      0.96        93\n",
      "           5       0.93      0.92      0.93        91\n",
      "           6       0.92      0.98      0.95        91\n",
      "           7       0.91      0.95      0.93        88\n",
      "           8       0.90      0.91      0.90        88\n",
      "           9       0.86      0.87      0.86        89\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       899\n",
      "   macro avg       0.92      0.92      0.92       899\n",
      "weighted avg       0.92      0.92      0.92       899\n",
      "\n",
      "[[89  0  1  0  0  0  0  0  0  0]\n",
      " [ 0 77  5  2  0  0  7  0  1  1]\n",
      " [ 0  1 81  0  0  0  0  1  3  0]\n",
      " [ 0  0  2 79  0  1  0  2  2  4]\n",
      " [ 0  0  0  0 88  0  0  3  2  0]\n",
      " [ 0  1  1  0  1 84  0  0  0  4]\n",
      " [ 1  0  0  0  1  0 89  0  0  0]\n",
      " [ 0  2  0  0  0  0  0 84  0  2]\n",
      " [ 0  3  1  0  0  0  1  1 80  2]\n",
      " [ 0  0  0  5  0  5  0  1  1 77]]\n"
     ]
    }
   ],
   "source": [
    "print('F1_SCORE :', f1_score(np.argmax(yans, axis=1), pred_test, average='macro'))\n",
    "print(classification_report(np.argmax(yans, axis=1), pred_test))\n",
    "print(confusion_matrix(np.argmax(yans, axis=1), pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RFECV_wr(RFECV):\n",
    "    \n",
    "    def __init__(self, C=1.0,\n",
    "                       step=1, min_features_to_select=1, cv='warn',\n",
    "                       scoring=None, verbose=0, n_jobs=None):\n",
    "        estimator = LogisticRegression(\n",
    "            penalty='l1',\n",
    "            C=100,\n",
    "            multi_class='multinomial',\n",
    "            solver='saga',\n",
    "            max_iter=10000)\n",
    "        super().__init__(estimator, step=step,\n",
    "                         min_features_to_select=min_features_to_select,\n",
    "                         cv=cv, scoring=scoring, verbose=verbose, n_jobs=n_jobs)\n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        if 'C' in params:\n",
    "            self.estimator.set_params(C=params['C'])\n",
    "        return self\n",
    "\n",
    "feature_selector = RFECV_wr(min_features_to_select=5,\n",
    "                             scoring=f1_scorer,\n",
    "                             step=15,\n",
    "                             verbose=0,\n",
    "                             cv=20,\n",
    "                             n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=0.001 .........................................................\n",
      "[CV] .......................................... C=0.001, total=   0.2s\n",
      "[CV] C=0.01 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................................... C=0.01, total=   0.3s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................................ C=0.1, total=   2.3s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ............................................ C=1.0, total=  12.8s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] ........................................... C=10.0, total= 2.1min\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] .......................................... C=100.0, total= 4.6min\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ......................................... C=1000.0, total= 7.0min\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] .......................................... C=0.001, total=   0.2s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] ........................................... C=0.01, total=   0.4s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................................ C=0.1, total=   2.3s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ............................................ C=1.0, total=  14.2s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] ........................................... C=10.0, total= 1.8min\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] .......................................... C=100.0, total= 3.9min\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ......................................... C=1000.0, total= 5.2min\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] .......................................... C=0.001, total=   0.2s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] ........................................... C=0.01, total=   0.3s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................................ C=0.1, total=   2.3s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ............................................ C=1.0, total=  13.8s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] ........................................... C=10.0, total= 2.3min\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] .......................................... C=100.0, total= 5.5min\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ......................................... C=1000.0, total= 6.0min\n",
      "CPU times: user 39min 18s, sys: 0 ns, total: 39min 18s\n",
      "Wall time: 39min 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed: 39.3min finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_scores, test_scores = validation_curve(\n",
    "    feature_selector,\n",
    "    np.hstack(pred_train_all_list), np.argmax(ytrain, axis=1),\n",
    "    param_name=param_name, param_range=param_range,\n",
    "    cv=cv_splitter, n_jobs=-1, verbose=2, scoring=f1_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e-03, 1.80008020e-02, 1.80919656e-02],\n",
       "       [1.00000000e-02, 1.81908749e-02, 1.82688944e-02],\n",
       "       [1.00000000e-01, 5.43982236e-01, 5.14956913e-01],\n",
       "       [1.00000000e+00, 8.31884603e-01, 7.80136116e-01],\n",
       "       [1.00000000e+01, 9.66674265e-01, 8.75295491e-01],\n",
       "       [1.00000000e+02, 9.98288982e-01, 8.78200716e-01],\n",
       "       [1.00000000e+03, 1.00000000e+00, 8.77806123e-01]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "np.c_[param_range, train_scores_mean, test_scores_mean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd6302415f8>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEaCAYAAAD+E0veAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd65c30b320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Validation Curve\")\n",
    "plt.xlabel(\"param\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "'''RFE'''\n",
    "\n",
    "param_grid = {\n",
    "            'C' : param_range,\n",
    "        }\n",
    "\n",
    "ins_splitter = StratifiedShuffleSplit(n_splits=100, test_size=0.5, random_state=0)\n",
    "var_idx_all = np.arange(xtrain.shape[1])\n",
    "#threshold = 0.85\n",
    "threshold = 0.30\n",
    "importances = np.zeros((xtrain.shape[1],))\n",
    "predictions = pd.DataFrame()\n",
    "#preds_all = pd.DataFrame()\n",
    "pred_all_list = []\n",
    "pred_train_all_list = []\n",
    "counter = 0\n",
    "np.random.seed(10001)\n",
    "\n",
    "feature_selector = RFECV()\n",
    "\n",
    "\n",
    "print(\"counter  | val_f1    |  val_r2    \")\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "for train_index, val_index in ins_splitter.split(xtrain, ytrain):\n",
    "    x_train_tr, x_train_val = xtrain[train_index], xtrain[val_index]\n",
    "    y_train_tr, y_train_val = ytrain[train_index], ytrain[val_index]\n",
    "    \n",
    "    \n",
    "    #estimator = LGBMRegressor(min_child_samples=50, reg_alpha=100)\n",
    "    estimator = RBFClassifier(\n",
    "        num_lm=2,\n",
    "        lm_select_from_x=True,\n",
    "        random_state=None,\n",
    "        lr=0.02, gamma='scale',\n",
    "        epochs=500, batch_size=1024, verbose=0\n",
    "    )\n",
    "    estimator.fit(x_train_tr, y_train_tr)\n",
    "    \n",
    "    # score our fitted model on validation data\n",
    "    val_y_pred = estimator.predict(x_train_val)\n",
    "    val_mse = mean_squared_error(np.argmax(y_train_val,axis=1), val_y_pred)\n",
    "    val_mae = mean_absolute_error(np.argmax(y_train_val,axis=1), val_y_pred)\n",
    "    val_kappa = 0.0\n",
    "    val_f1 = f1_score(np.argmax(y_train_val,axis=1), val_y_pred, average='macro')\n",
    "    val_cos = cosine_similarity(np.argmax(y_train_val,axis=1).reshape(1, -1), val_y_pred.reshape(1, -1))[0][0]\n",
    "    val_dst = euclidean_distances(np.argmax(y_train_val,axis=1).reshape(1, -1), val_y_pred.reshape(1, -1))[0][0]\n",
    "    val_r2  = r2_score(np.argmax(y_train_val,axis=1), val_y_pred)\n",
    "    gamma = estimator.current_gamma()\n",
    "    \n",
    "    if val_f1 > threshold:\n",
    "        message = '<-- OK'\n",
    "        pred_train_all = estimator.predict_proba(xtrain)\n",
    "        pred_train_all_list.append(pred_train_all)\n",
    "        pred_all = estimator.predict_proba(xtest)\n",
    "        pred_all_list.append(pred_all)\n",
    "        #preds_all = pd.concat([preds_all, pd.DataFrame(pred_all)], axis=1)\n",
    "        #prediction = grid_search.best_estimator_.predict(x_test0)\n",
    "        #predictions = pd.concat([predictions, pd.DataFrame(prediction)], axis=1)\n",
    "        #importances += estimator.feature_importances_\n",
    "        #filename = 'model-{}.sav'.format(counter)\n",
    "        #joblib.dump(estimator, filename)\n",
    "    else:\n",
    "        message = '<-- skipping'\n",
    "\n",
    "    print(\"{0:5}    |  {3:.4f}   |  {4:.4f}   {5:5e} {7}  \".format(\n",
    "        counter,\n",
    "        val_mse,\n",
    "        val_mae,\n",
    "        val_f1,\n",
    "        val_r2,\n",
    "        gamma,\n",
    "        0,\n",
    "        message))\n",
    "    \n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
